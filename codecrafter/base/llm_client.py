"""
LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ - å„ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã¨ã®çµ±åˆ
"""
import os
from typing import Any, Dict, Optional, List
from abc import ABC, abstractmethod

from langchain.schema import BaseMessage, HumanMessage, AIMessage, SystemMessage
from langchain.callbacks.manager import CallbackManagerForLLMRun
from langchain.llms.base import LLM

try:
    from langchain_openai import ChatOpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

try:
    from langchain_anthropic import ChatAnthropic
    ANTHROPIC_AVAILABLE = True
except ImportError:
    ANTHROPIC_AVAILABLE = False

try:
    from langchain_groq import ChatGroq
    GROQ_AVAILABLE = True
except ImportError:
    GROQ_AVAILABLE = False

# OpenRouterã¯OpenAIäº’æ›ãªã®ã§ã€OpenAIãŒåˆ©ç”¨å¯èƒ½ãªã‚‰OpenRouterã‚‚åˆ©ç”¨å¯èƒ½
OPENROUTER_AVAILABLE = OPENAI_AVAILABLE

from .config import config_manager


class LLMClientError(Exception):
    """LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¨ãƒ©ãƒ¼"""
    pass


class BaseLLMClient(ABC):
    """LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åŸºåº•ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
    
    @abstractmethod
    def chat(self, messages: List[Dict[str, str]]) -> str:
        """ãƒãƒ£ãƒƒãƒˆå½¢å¼ã§ã®å¯¾è©±"""
        pass
    
    @abstractmethod
    def is_available(self) -> bool:
        """ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆ©ç”¨å¯èƒ½ã‹ã©ã†ã‹"""
        pass


class OpenAIClient(BaseLLMClient):
    """OpenAI GPTã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"""
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__(config)
        if not OPENAI_AVAILABLE:
            raise LLMClientError("langchain-openai ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        api_key = config_manager.get_api_key('openai')
        if not api_key:
            raise LLMClientError("OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        self.client = ChatOpenAI(
            model=config.get('model', 'gpt-4-turbo-preview'),
            temperature=config.get('temperature', 0.1),
            max_tokens=config.get('max_tokens', 4096),
            openai_api_key=api_key,
        )
    
    def chat(self, messages: List[Dict[str, str]]) -> str:
        """ãƒãƒ£ãƒƒãƒˆå½¢å¼ã§ã®å¯¾è©±"""
        try:
            # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’LangChainå½¢å¼ã«å¤‰æ›
            langchain_messages = []
            for msg in messages:
                role = msg.get('role', 'user')
                content = msg.get('content', '')
                
                if role == 'system':
                    langchain_messages.append(SystemMessage(content=content))
                elif role == 'assistant':
                    langchain_messages.append(AIMessage(content=content))
                else:  # user
                    langchain_messages.append(HumanMessage(content=content))
            
            # LLMã«é€ä¿¡
            response = self.client.invoke(langchain_messages)
            return response.content
            
        except Exception as e:
            raise LLMClientError(f"OpenAI APIå‘¼ã³å‡ºã—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    
    def is_available(self) -> bool:
        """ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆ©ç”¨å¯èƒ½ã‹ã©ã†ã‹"""
        return OPENAI_AVAILABLE and config_manager.get_api_key('openai') is not None


class AnthropicClient(BaseLLMClient):
    """Anthropic Claudeã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"""
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__(config)
        if not ANTHROPIC_AVAILABLE:
            raise LLMClientError("langchain-anthropic ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        api_key = config_manager.get_api_key('anthropic')
        if not api_key:
            raise LLMClientError("ANTHROPIC_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        self.client = ChatAnthropic(
            model=config.get('model', 'claude-3-5-sonnet-20241022'),
            temperature=config.get('temperature', 0.1),
            max_tokens=config.get('max_tokens', 4096),
            anthropic_api_key=api_key,
        )
    
    def chat(self, messages: List[Dict[str, str]]) -> str:
        """ãƒãƒ£ãƒƒãƒˆå½¢å¼ã§ã®å¯¾è©±"""
        try:
            # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’LangChainå½¢å¼ã«å¤‰æ›
            langchain_messages = []
            for msg in messages:
                role = msg.get('role', 'user')
                content = msg.get('content', '')
                
                if role == 'system':
                    langchain_messages.append(SystemMessage(content=content))
                elif role == 'assistant':
                    langchain_messages.append(AIMessage(content=content))
                else:  # user
                    langchain_messages.append(HumanMessage(content=content))
            
            # LLMã«é€ä¿¡
            response = self.client.invoke(langchain_messages)
            return response.content
            
        except Exception as e:
            raise LLMClientError(f"Anthropic APIå‘¼ã³å‡ºã—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    
    def is_available(self) -> bool:
        """ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆ©ç”¨å¯èƒ½ã‹ã©ã†ã‹"""
        return ANTHROPIC_AVAILABLE and config_manager.get_api_key('anthropic') is not None


class GroqClient(BaseLLMClient):
    """Groq LLamaã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"""
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__(config)
        if not GROQ_AVAILABLE:
            raise LLMClientError("langchain-groq ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        api_key = config_manager.get_api_key('groq')
        if not api_key:
            raise LLMClientError("GROQ_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        self.client = ChatGroq(
            model=config.get('model'),
            temperature=config.get('temperature', 0.1),
            max_tokens=config.get('max_tokens', 8192),
            groq_api_key=api_key,
        )
    
    def chat(self, messages: List[Dict[str, str]]) -> str:
        """ãƒãƒ£ãƒƒãƒˆå½¢å¼ã§ã®å¯¾è©±"""
        try:
            # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æ¤œè¨¼ã¨å‰å‡¦ç†
            if not messages:
                raise LLMClientError("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒç©ºã§ã™")
            
            # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’LangChainå½¢å¼ã«å¤‰æ›
            langchain_messages = []
            for msg in messages:
                role = msg.get('role', 'user')
                content = msg.get('content', '')
                
                # ç©ºã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ã‚¹ã‚­ãƒƒãƒ—
                if not content or not content.strip():
                    continue
                
                # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®é•·ã•åˆ¶é™ï¼ˆGroq APIã®åˆ¶é™ã‚’è€ƒæ…®ï¼‰
                if len(content) > 32000:  # å®‰å…¨ãƒãƒ¼ã‚¸ãƒ³ã‚’è¨­ã‘ã¦32Kæ–‡å­—ã«åˆ¶é™
                    content = content[:32000] + "...(çœç•¥)"
                
                if role == 'system':
                    langchain_messages.append(SystemMessage(content=content))
                elif role == 'assistant':
                    langchain_messages.append(AIMessage(content=content))
                else:  # user
                    langchain_messages.append(HumanMessage(content=content))
            
            if not langchain_messages:
                raise LLMClientError("æœ‰åŠ¹ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒã‚ã‚Šã¾ã›ã‚“")
            
            # LLMã«é€ä¿¡
            response = self.client.invoke(langchain_messages)
            
            if not response or not hasattr(response, 'content'):
                raise LLMClientError("Groq APIã‹ã‚‰ç„¡åŠ¹ãªå¿œç­”ã‚’å—ä¿¡ã—ã¾ã—ãŸ")
            
            return response.content
            
        except Exception as e:
            # ã‚ˆã‚Šè©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’æä¾›
            import traceback
            import logging
            
            logger = logging.getLogger(__name__)
            error_msg = str(e)
            
            # è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’å–å¾—
            error_details = traceback.format_exc()
            logger.error(f"ğŸ” Groq API ã‚¨ãƒ©ãƒ¼è©³ç´°:\n{error_details}")
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒœãƒ‡ã‚£ã®è©³ç´°ã‚’å–å¾—ï¼ˆã‚‚ã—ã‚ã‚Œã°ï¼‰
            response_detail = ""
            if hasattr(e, 'response') and e.response:
                try:
                    if hasattr(e.response, 'text'):
                        response_detail = f"\nğŸ“„ ãƒ¬ã‚¹ãƒãƒ³ã‚¹è©³ç´°: {e.response.text}"
                    elif hasattr(e.response, 'content'):
                        response_detail = f"\nğŸ“„ ãƒ¬ã‚¹ãƒãƒ³ã‚¹è©³ç´°: {e.response.content}"
                    logger.error(f"ğŸ” Groq API ãƒ¬ã‚¹ãƒãƒ³ã‚¹è©³ç´°: {response_detail}")
                except Exception as resp_err:
                    logger.error(f"ãƒ¬ã‚¹ãƒãƒ³ã‚¹è©³ç´°å–å¾—ã‚¨ãƒ©ãƒ¼: {resp_err}")
            
            # HTTPã‚¨ãƒ©ãƒ¼ã®è©³ç´°æƒ…å ±ã‚’å–å¾—
            if hasattr(e, '__class__') and hasattr(e.__class__, '__name__'):
                error_type = e.__class__.__name__
                logger.error(f"ğŸ” ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—: {error_type}")
            
            # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«è©³ç´°æƒ…å ±ã‚’å«ã‚ã‚‹
            detailed_msg = f"{error_msg}{response_detail}"
            
            if "400" in error_msg or "Bad Request" in error_msg:
                raise LLMClientError(f"Groq API ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼ (400): ãƒªã‚¯ã‚¨ã‚¹ãƒˆå†…å®¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„{detailed_msg}")
            elif "401" in error_msg or "Unauthorized" in error_msg:
                raise LLMClientError(f"Groq API èªè¨¼ã‚¨ãƒ©ãƒ¼ (401): API ã‚­ãƒ¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„{detailed_msg}")
            elif "429" in error_msg or "rate limit" in error_msg.lower():
                raise LLMClientError(f"Groq API ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼ (429): ã—ã°ã‚‰ãå¾…ã£ã¦ã‹ã‚‰å†è©¦è¡Œã—ã¦ãã ã•ã„{detailed_msg}")
            elif "500" in error_msg or "Internal Server Error" in error_msg:
                raise LLMClientError(f"Groq API ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼ (500): ã—ã°ã‚‰ãå¾…ã£ã¦ã‹ã‚‰å†è©¦è¡Œã—ã¦ãã ã•ã„{detailed_msg}")
            else:
                raise LLMClientError(f"Groq APIå‘¼ã³å‡ºã—ã«å¤±æ•—ã—ã¾ã—ãŸ: {detailed_msg}")
    
    def is_available(self) -> bool:
        """ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆ©ç”¨å¯èƒ½ã‹ã©ã†ã‹"""
        return GROQ_AVAILABLE and config_manager.get_api_key('groq') is not None


class OpenRouterClient(BaseLLMClient):
    """OpenRouter APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆOpenAIäº’æ›ï¼‰"""
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__(config)
        if not OPENROUTER_AVAILABLE:
            raise LLMClientError("langchain-openai ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼ˆOpenRouterç”¨ï¼‰")
        
        api_key = config_manager.get_api_key('openrouter')
        if not api_key:
            raise LLMClientError("OPENROUTER_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        # OpenRouterã¯OpenAIäº’æ›API
        self.client = ChatOpenAI(
            model=config.get('model', 'anthropic/claude-3-sonnet'),
            temperature=config.get('temperature', 0.1),
            max_tokens=config.get('max_tokens', 4096),
            openai_api_key=api_key,
            openai_api_base="https://openrouter.ai/api/v1",
            model_kwargs={
                "extra_headers": {
                    "HTTP-Referer": "https://duckflow.app",
                    "X-Title": "Duckflow AI Coding Agent"
                }
            }
        )
    
    def chat(self, messages: List[Dict[str, str]]) -> str:
        """ãƒãƒ£ãƒƒãƒˆå½¢å¼ã§ã®å¯¾è©±"""
        # è¾æ›¸å½¢å¼ã‚’LangChainãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«å¤‰æ›
        langchain_messages = []
        for msg in messages:
            role = msg['role']
            content = msg['content']
            
            if role == 'user':
                langchain_messages.append(HumanMessage(content=content))
            elif role == 'assistant':
                langchain_messages.append(AIMessage(content=content))
            elif role == 'system':
                langchain_messages.append(SystemMessage(content=content))
        
        try:
            response = self.client.invoke(langchain_messages)
            return response.content
        except Exception as e:
            raise LLMClientError(f"OpenRouter API error: {str(e)}")
    
    def is_available(self) -> bool:
        """åˆ©ç”¨å¯èƒ½ã‹ã©ã†ã‹ã‚’ç¢ºèª"""
        return OPENROUTER_AVAILABLE and config_manager.get_api_key('openrouter') is not None


class MockClient(BaseLLMClient):
    """ãƒ¢ãƒƒã‚¯ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰"""
    
    def chat(self, messages: List[Dict[str, str]]) -> str:
        """ãƒ¢ãƒƒã‚¯å¿œç­”ã‚’è¿”ã™"""
        return "ã“ã¡ã‚‰ã¯ãƒ¢ãƒƒã‚¯ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã§ã™ã€‚å®Ÿéš›ã®LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ã€é©åˆ‡ãªAPIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚"
    
    def is_available(self) -> bool:
        """å¸¸ã«åˆ©ç”¨å¯èƒ½"""
        return True


class LLMManager:
    """LLMç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.config = config_manager.load_config()
        self.current_client: Optional[BaseLLMClient] = None
        self.summary_client: Optional[BaseLLMClient] = None  # è¦ç´„ç”¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
        self._initialize_client()
    
    def _initialize_client(self) -> None:
        """ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–"""
        # ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
        provider = self.config.llm.provider.lower()
        llm_config = config_manager.get_llm_config()
        
        try:
            if provider == 'openai':
                self.current_client = OpenAIClient(llm_config)
            elif provider == 'anthropic':
                self.current_client = AnthropicClient(llm_config)
            elif provider == 'groq':
                self.current_client = GroqClient(llm_config)
            elif provider == 'openrouter':
                self.current_client = OpenRouterClient(llm_config)
            else:
                # æœªå¯¾å¿œã®ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã¾ãŸã¯è¨­å®šä¸å‚™ã®å ´åˆã¯ãƒ¢ãƒƒã‚¯ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
                self.current_client = MockClient(llm_config)
                
        except LLMClientError as e:
            print(f"è­¦å‘Š: LLMã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            print("ãƒ¢ãƒƒã‚¯ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            self.current_client = MockClient(llm_config)
        
        # è¦ç´„ç”¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ– (ã‚¹ãƒ†ãƒƒãƒ—2c)
        try:
            summary_provider = self.config.summary_llm.provider.lower()
            summary_config = getattr(self.config.summary_llm, summary_provider, {})
            if isinstance(summary_config, dict):
                if summary_provider == 'openai':
                    self.summary_client = OpenAIClient(summary_config)
                elif summary_provider == 'anthropic':
                    self.summary_client = AnthropicClient(summary_config)
                elif summary_provider == 'groq':
                    self.summary_client = GroqClient(summary_config)
                elif summary_provider == 'openrouter':
                    self.summary_client = OpenRouterClient(summary_config)
                else:
                    self.summary_client = self.current_client  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            else:
                self.summary_client = self.current_client  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        except Exception:
            # è¦ç´„ç”¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ã«å¤±æ•—ã—ãŸå ´åˆã¯ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½¿ç”¨
            self.summary_client = self.current_client
    
    def chat(self, message: str, system_prompt: Optional[str] = None, client_type: str = "main") -> str:
        """ã‚·ãƒ³ãƒ—ãƒ«ãªãƒãƒ£ãƒƒãƒˆ
        
        Args:
            message: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            system_prompt: ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            client_type: ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¿ã‚¤ãƒ— ("main" ã¾ãŸã¯ "summary")
        
        Returns:
            LLMã®å¿œç­”
        """
        messages = []
        
        if system_prompt:
            messages.append({
                'role': 'system',
                'content': system_prompt
            })
        
        messages.append({
            'role': 'user',
            'content': message
        })
        
        # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ã«å¿œã˜ã¦é©åˆ‡ãªã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’é¸æŠ
        client = self.summary_client if client_type == "summary" else self.current_client
        return client.chat(messages)
    
    def chat_with_history(self, messages: List[Dict[str, str]]) -> str:
        """å±¥æ­´ä»˜ããƒãƒ£ãƒƒãƒˆ"""
        return self.current_client.chat(messages)
    
    def get_provider_name(self) -> str:
        """ç¾åœ¨ã®ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼åã‚’å–å¾—"""
        if isinstance(self.current_client, OpenAIClient):
            return "OpenAI"
        elif isinstance(self.current_client, AnthropicClient):
            return "Anthropic"
        elif isinstance(self.current_client, GroqClient):
            return "Groq"
        elif isinstance(self.current_client, OpenRouterClient):
            return "OpenRouter"
        elif isinstance(self.current_client, MockClient):
            return "Mock"
        else:
            return "Unknown"
    
    def is_mock_client(self) -> bool:
        """ãƒ¢ãƒƒã‚¯ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‹ã©ã†ã‹"""
        return isinstance(self.current_client, MockClient)



    def get_default_client(self) -> BaseLLMClient:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å–å¾— (å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚)
        
        Returns:
            ç¾åœ¨ã®ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
        """
        return self.current_client
    
    def get_client(self, client_type: str = "main") -> BaseLLMClient:
        """æŒ‡å®šã•ã‚ŒãŸã‚¿ã‚¤ãƒ—ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å–å¾—
        
        Args:
            client_type: ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¿ã‚¤ãƒ— ("main" ã¾ãŸã¯ "summary")
            
        Returns:
            æŒ‡å®šã•ã‚ŒãŸã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
        """
        if client_type == "summary":
            return self.summary_client
        return self.current_client

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ãªLLMç®¡ç†ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
llm_manager = LLMManager()