"""
å¯¾è©±è¨˜æ†¶ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ  (ã‚¹ãƒ†ãƒƒãƒ—2c)
çŸ­æœŸãƒ»ä¸­æœŸè¨˜æ†¶ã¨è¦ç´„æ©Ÿèƒ½ã‚’å®Ÿè£…
"""
import tiktoken
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime

from ..base.llm_client import llm_manager, LLMClientError
from ..base.config import config_manager
from ..state.agent_state import ConversationMessage


class ConversationMemory:
    """å¯¾è©±è¨˜æ†¶ç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.config = config_manager.load_config()
        self.memory_config = self.config.memory
        
        # ãƒˆãƒ¼ã‚¯ãƒ³ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼åˆæœŸåŒ–ï¼ˆGPTãƒ™ãƒ¼ã‚¹ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’ä½¿ç”¨ï¼‰
        try:
            self.encoding = tiktoken.get_encoding("cl100k_base")  # GPT-4ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼
        except Exception:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç°¡æ˜“çš„ãªæ–‡å­—æ•°ãƒ™ãƒ¼ã‚¹æ¨å®š
            self.encoding = None
    
    def count_tokens(self, text: str) -> int:
        """ãƒ†ã‚­ã‚¹ãƒˆã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’æ¨å®š
        
        Args:
            text: ã‚«ã‚¦ãƒ³ãƒˆã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
            
        Returns:
            æ¨å®šãƒˆãƒ¼ã‚¯ãƒ³æ•°
        """
        if self.encoding:
            return len(self.encoding.encode(text))
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æ–‡å­—æ•° / 4 (æ—¥æœ¬èªãƒ»è‹±èªæ··åˆã®ç²—ã„æ¨å®š)
            return len(text) // 4
    
    def calculate_conversation_tokens(self, messages: List[ConversationMessage]) -> int:
        """å¯¾è©±å±¥æ­´ã®ç·ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’è¨ˆç®—
        
        Args:
            messages: å¯¾è©±ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆ
            
        Returns:
            ç·ãƒˆãƒ¼ã‚¯ãƒ³æ•°
        """
        total_tokens = 0
        for message in messages:
            # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å†…å®¹ + ãƒ­ãƒ¼ãƒ«æƒ…å ± + ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
            content_tokens = self.count_tokens(message.content)
            role_tokens = self.count_tokens(f"role:{message.role}")
            total_tokens += content_tokens + role_tokens + 10  # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”¨ä½™è£•
        
        return total_tokens
    
    def should_summarize(self, messages: List[ConversationMessage]) -> bool:
        """è¦ç´„ãŒå¿…è¦ã‹ã©ã†ã‹ã‚’åˆ¤å®š
        
        Args:
            messages: å¯¾è©±ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆ
            
        Returns:
            è¦ç´„ãŒå¿…è¦ãªå ´åˆTrue
        """
        total_tokens = self.calculate_conversation_tokens(messages)
        trigger_tokens = self.memory_config.medium_term.get("summary_trigger_tokens", 4000)
        
        return total_tokens > trigger_tokens
    
    def create_conversation_summary(
        self, 
        messages: List[ConversationMessage],
        existing_summary: Optional[str] = None
    ) -> str:
        """å¯¾è©±å±¥æ­´ã®è¦ç´„ã‚’ä½œæˆ
        
        Args:
            messages: è¦ç´„ã™ã‚‹å¯¾è©±ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆ
            existing_summary: æ—¢å­˜ã®è¦ç´„ï¼ˆã‚ã‚Œã°ï¼‰
            
        Returns:
            è¦ç´„ãƒ†ã‚­ã‚¹ãƒˆ
        """
        try:
            # è¦ç´„ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
            summary_prompt = self._build_summary_prompt(messages, existing_summary)
            
            # è¦ç´„ç”¨LLMã§è¦ç´„å®Ÿè¡Œ
            summary = llm_manager.chat(
                message="ä»¥ä¸‹ã®å¯¾è©±ã‚’è¦ç´„ã—ã¦ãã ã•ã„ï¼š",
                system_prompt=summary_prompt,
                client_type="summary"
            )
            
            return summary.strip()
            
        except LLMClientError as e:
            # è¦ç´„ã«å¤±æ•—ã—ãŸå ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            return self._create_fallback_summary(messages, existing_summary)
    
    def _build_summary_prompt(
        self, 
        messages: List[ConversationMessage],
        existing_summary: Optional[str] = None
    ) -> str:
        """è¦ç´„ç”¨ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
        
        Args:
            messages: å¯¾è©±ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆ
            existing_summary: æ—¢å­˜ã®è¦ç´„
            
        Returns:
            è¦ç´„ç”¨ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        """
        base_prompt = """ã‚ãªãŸã¯å¯¾è©±å±¥æ­´ã®è¦ç´„å°‚é–€AIã§ã™ã€‚ä»¥ä¸‹ã®æŒ‡ç¤ºã«å¾“ã£ã¦å¯¾è©±ã‚’è¦ç´„ã—ã¦ãã ã•ã„ï¼š

**è¦ç´„ã®ç›®æ¨™:**
- é‡è¦ãªæŒ‡ç¤ºã€æ±ºå®šäº‹é …ã€é€²è¡Œä¸­ã®ã‚¿ã‚¹ã‚¯ã‚’ä¿æŒ
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç›®æ¨™ã‚„æ„å›³ã‚’æ˜ç¢ºã«è¨˜éŒ²
- AI ã®å¿œç­”ã‚„ææ¡ˆå†…å®¹ã‚’ç°¡æ½”ã«ã¾ã¨ã‚ã‚‹
- æ–‡è„ˆã®ç¶™ç¶šæ€§ã‚’ä¿ã¤

**è¦ç´„ã®å½¢å¼:**
1. **ã‚»ãƒƒã‚·ãƒ§ãƒ³ç›®æ¨™**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒé”æˆã—ã‚ˆã†ã¨ã—ã¦ã„ã‚‹ã“ã¨
2. **é‡è¦ãªæ±ºå®š**: è¡Œã‚ã‚ŒãŸé‡è¦ãªåˆ¤æ–­ã‚„è¨­å®š
3. **é€²è¡ŒçŠ¶æ³**: å®Œäº†ã—ãŸã‚¿ã‚¹ã‚¯ã¨æœªå®Œäº†ã®ã‚¿ã‚¹ã‚¯
4. **é‡è¦ãªæƒ…å ±**: è¦šãˆã¦ãŠãã¹ãæŠ€è¡“çš„è©³ç´°ã‚„åˆ¶ç´„

**è¦ç´„ã®åˆ¶ç´„:**
- ç›®æ¨™ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {target_tokens}ãƒˆãƒ¼ã‚¯ãƒ³ä»¥å†…
- å…·ä½“çš„ãªå›ºæœ‰åè©ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åã€å¤‰æ•°åãªã©ï¼‰ã¯ä¿æŒ
- æ„Ÿæƒ…çš„ãªè¡¨ç¾ã¯é™¤å»ã—ã€äº‹å®Ÿã®ã¿ã‚’è¨˜éŒ²"""

        # æ—¢å­˜ã®è¦ç´„ãŒã‚ã‚‹å ´åˆã¯çµ±åˆæŒ‡ç¤ºã‚’è¿½åŠ 
        if existing_summary:
            base_prompt += f"""

**æ—¢å­˜ã®è¦ç´„:**
{existing_summary}

**æŒ‡ç¤º**: æ—¢å­˜ã®è¦ç´„ã¨æ–°ã—ã„å¯¾è©±ã‚’çµ±åˆã—ã€é‡è¤‡ã‚’æ’é™¤ã—ã¦æ›´æ–°ã•ã‚ŒãŸè¦ç´„ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚"""

        # å¯¾è©±å±¥æ­´ã‚’è¿½åŠ 
        conversation_text = self._format_messages_for_summary(messages)
        base_prompt += f"""

**è¦ç´„å¯¾è±¡ã®å¯¾è©±:**
{conversation_text}"""

        return base_prompt.format(
            target_tokens=self.memory_config.medium_term.get("summary_target_tokens", 500)
        )
    
    def _format_messages_for_summary(self, messages: List[ConversationMessage]) -> str:
        """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¦ç´„ç”¨ã«æ•´å½¢
        
        Args:
            messages: å¯¾è©±ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆ
            
        Returns:
            æ•´å½¢ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
        """
        formatted_parts = []
        
        for message in messages:
            timestamp = message.timestamp.strftime("%H:%M")
            role_label = {
                "user": "ãƒ¦ãƒ¼ã‚¶ãƒ¼",
                "assistant": "AI", 
                "system": "ã‚·ã‚¹ãƒ†ãƒ "
            }.get(message.role, message.role)
            
            content = message.content[:1000]  # é•·ã™ãã‚‹å ´åˆã¯åˆ‡ã‚Šè©°ã‚
            formatted_parts.append(f"[{timestamp}] {role_label}: {content}")
        
        return "\n".join(formatted_parts)
    
    def _create_fallback_summary(
        self, 
        messages: List[ConversationMessage],
        existing_summary: Optional[str] = None
    ) -> str:
        """LLMè¦ç´„ã«å¤±æ•—ã—ãŸå ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¦ç´„
        
        Args:
            messages: å¯¾è©±ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆ
            existing_summary: æ—¢å­˜ã®è¦ç´„
            
        Returns:
            ç°¡æ˜“è¦ç´„ãƒ†ã‚­ã‚¹ãƒˆ
        """
        # åŸºæœ¬çµ±è¨ˆ
        user_messages = [m for m in messages if m.role == "user"]
        ai_messages = [m for m in messages if m.role == "assistant"]
        
        # æœ€åˆã¨æœ€å¾Œã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰ç°¡æ˜“è¦ç´„ã‚’ç”Ÿæˆ
        start_time = messages[0].timestamp.strftime("%H:%M")
        end_time = messages[-1].timestamp.strftime("%H:%M")
        
        fallback_summary = f"""**ç°¡æ˜“è¦ç´„ ({start_time}-{end_time})**
- å¯¾è©±ã‚¿ãƒ¼ãƒ³æ•°: {len(user_messages)}å›
- æœ€åˆã®è¦æ±‚: {user_messages[0].content[:100] if user_messages else "ä¸æ˜"}...
- æœ€å¾Œã®å¿œç­”: {ai_messages[-1].content[:100] if ai_messages else "ä¸æ˜"}..."""

        if existing_summary:
            fallback_summary = f"{existing_summary}\n\n{fallback_summary}"
        
        return fallback_summary
    
    def trim_conversation_history(
        self, 
        messages: List[ConversationMessage],
        summary: str
    ) -> Tuple[str, List[ConversationMessage]]:
        """å¯¾è©±å±¥æ­´ã‚’ãƒˆãƒªãƒ ï¼ˆè¦ç´„ + æœ€æ–°æ•°ã‚¿ãƒ¼ãƒ³ã®ã¿ä¿æŒï¼‰
        
        Args:
            messages: å…¨å¯¾è©±ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆ
            summary: ä½œæˆã•ã‚ŒãŸè¦ç´„
            
        Returns:
            (æ›´æ–°ã•ã‚ŒãŸè¦ç´„, ä¿æŒã™ã‚‹æœ€æ–°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆ)
        """
        keep_turns = self.memory_config.medium_term.get("keep_recent_turns", 3)
        
        # æœ€æ–°ã®æŒ‡å®šã‚¿ãƒ¼ãƒ³æ•°ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒšã‚¢ã‚’ä¿æŒ
        if len(messages) <= keep_turns * 2:  # user + assistant ã®ãƒšã‚¢
            return summary, messages
        
        # ğŸ”§ ä¿®æ­£: æœ€æ–°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å¿…ãšä¿æŒã™ã‚‹å®‰å…¨ç­–
        # å°‘ãªãã¨ã‚‚æœ€æ–°ã®6ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆ3ãƒšã‚¢ç›¸å½“ï¼‰ã‚’ä¿æŒ
        min_keep_messages = keep_turns * 2
        
        # æœ€æ–°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰ã•ã‹ã®ã¼ã£ã¦ä¿æŒå¯¾è±¡ã‚’æ±ºå®š
        if len(messages) > min_keep_messages:
            # æœ€æ–°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒå˜ç‹¬ã®userãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å ´åˆã¯+1ã—ã¦ä¿æŒ
            keep_count = min_keep_messages
            if messages[-1].role == "user":
                keep_count += 1  # æœ€æ–°ã®userãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å¿…ãšä¿æŒ
            
            recent_messages = messages[-keep_count:]
        else:
            recent_messages = messages
        
        return summary, recent_messages
    
    def get_memory_status(
        self, 
        messages: List[ConversationMessage],
        summary: Optional[str] = None
    ) -> Dict[str, Any]:
        """ãƒ¡ãƒ¢ãƒªçŠ¶æ…‹ã®çµ±è¨ˆæƒ…å ±ã‚’å–å¾—
        
        Args:
            messages: å¯¾è©±ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆ
            summary: ç¾åœ¨ã®è¦ç´„
            
        Returns:
            ãƒ¡ãƒ¢ãƒªçŠ¶æ…‹æƒ…å ±
        """
        total_tokens = self.calculate_conversation_tokens(messages)
        summary_tokens = self.count_tokens(summary) if summary else 0
        
        return {
            "total_messages": len(messages),
            "total_tokens": total_tokens,
            "summary_tokens": summary_tokens,
            "needs_summary": self.should_summarize(messages),
            "trigger_threshold": self.memory_config.medium_term.get("summary_trigger_tokens", 4000),
            "target_summary_tokens": self.memory_config.medium_term.get("summary_target_tokens", 500),
            "keep_recent_turns": self.memory_config.medium_term.get("keep_recent_turns", 3)
        }


# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
conversation_memory = ConversationMemory()