"""
ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚³ãƒ¼ãƒ‰ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–ã‚·ã‚¹ãƒ†ãƒ 
LangChainã¨ChromaDBã‚’ä½¿ç”¨ã—ã¦ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–
"""
import os
import time
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
from datetime import datetime

from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema import Document
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain_community.embeddings import HuggingFaceEmbeddings

from ..base.config import config_manager
from ..ui.rich_ui import rich_ui


class CodeDocument:
    """ã‚³ãƒ¼ãƒ‰ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’è¡¨ç¾ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(
        self,
        file_path: str,
        content: str,
        language: str,
        size: int,
        modified_time: datetime
    ):
        """ã‚³ãƒ¼ãƒ‰ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’åˆæœŸåŒ–
        
        Args:
            file_path: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            content: ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹
            language: ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èª
            size: ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º
            modified_time: æœ€çµ‚æ›´æ–°æ™‚åˆ»
        """
        self.file_path = file_path
        self.content = content
        self.language = language
        self.size = size
        self.modified_time = modified_time


class CodeIndexer:
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚³ãƒ¼ãƒ‰ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–ã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, project_path: str = "."):
        """ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚µãƒ¼ã‚’åˆæœŸåŒ–
        
        Args:
            project_path: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹
        """
        self.project_path = Path(project_path).resolve()
        self.config = config_manager.load_config()
        
        # ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢è¨­å®š
        self.vector_store_path = self.project_path / ".duckflow" / "vectorstore"
        self.vector_store: Optional[Chroma] = None
        
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å¯¾è±¡ã®æ‹¡å¼µå­
        self.supported_extensions = {
            '.py': 'python',
            '.js': 'javascript', 
            '.ts': 'typescript',
            '.jsx': 'jsx',
            '.tsx': 'tsx',
            '.java': 'java',
            '.cpp': 'cpp',
            '.c': 'c',
            '.cs': 'csharp',
            '.go': 'go',
            '.rs': 'rust',
            '.php': 'php',
            '.rb': 'ruby',
            '.swift': 'swift',
            '.kt': 'kotlin',
            '.scala': 'scala',
            '.md': 'markdown',
            '.yaml': 'yaml',
            '.yml': 'yaml',
            '.json': 'json',
            '.xml': 'xml',
            '.html': 'html',
            '.css': 'css',
            '.sql': 'sql',
            '.sh': 'bash',
            '.ps1': 'powershell',
        }
        
        # é™¤å¤–ã™ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        self.excluded_dirs = {
            '.git', '.svn', '.hg',
            'node_modules', '.venv', 'venv', '.env',
            '__pycache__', '.pytest_cache',
            'build', 'dist', 'target',
            '.idea', '.vscode',
            '.duckflow'
        }
        
        # ãƒ†ã‚­ã‚¹ãƒˆåˆ†å‰²è¨­å®š
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            length_function=len,
        )
        
        # åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«
        self.embeddings = self._initialize_embeddings()
    
    def _initialize_embeddings(self) -> Any:
        """åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–
        
        Returns:
            åˆæœŸåŒ–ã•ã‚ŒãŸåŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«
        """
        try:
            # OpenAI embeddings ã‚’å„ªå…ˆ
            if hasattr(self.config.llm, 'openai_api_key') and self.config.llm.openai_api_key:
                return OpenAIEmbeddings(
                    openai_api_key=self.config.llm.openai_api_key,
                    model="text-embedding-3-small"
                )
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: HuggingFace embeddingsï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ï¼‰
                rich_ui.print_message("OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒ­ãƒ¼ã‚«ãƒ«åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™", "warning")
                return HuggingFaceEmbeddings(
                    model_name="sentence-transformers/all-MiniLM-L6-v2",
                    model_kwargs={'device': 'cpu'}
                )
        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç°¡ç•¥åŒ–ã—ã¦è¡¨ç¤ºï¼ˆUnicodeå•é¡Œå›é¿ï¼‰
            print(f"Warning: Failed to initialize embedding model: {str(e)}")
            # æœ€å°é™ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            try:
                return HuggingFaceEmbeddings(
                    model_name="sentence-transformers/all-MiniLM-L6-v2",
                    model_kwargs={'device': 'cpu'}
                )
            except Exception:
                # æœ€çµ‚çš„ãªãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ - åŸ‹ã‚è¾¼ã¿ç„¡ã—ãƒ¢ãƒ¼ãƒ‰
                raise ValueError("RAGæ©Ÿèƒ½ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯OpenAI APIã‚­ãƒ¼ã¾ãŸã¯sentence-transformersãŒå¿…è¦ã§ã™")
    
    def scan_project(self) -> List[CodeDocument]:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå†…ã®ã‚³ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¹ã‚­ãƒ£ãƒ³
        
        Returns:
            æ¤œå‡ºã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä¸€è¦§
        """
        code_docs = []
        scanned_files = 0
        
        rich_ui.print_message(f"ğŸ“ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ã‚¹ã‚­ãƒ£ãƒ³ä¸­: {self.project_path}", "info")
        
        for file_path in self.project_path.rglob("*"):
            if not file_path.is_file():
                continue
            
            # é™¤å¤–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒã‚§ãƒƒã‚¯
            if any(excluded in file_path.parts for excluded in self.excluded_dirs):
                continue
            
            # ã‚µãƒãƒ¼ãƒˆå¯¾è±¡ã®æ‹¡å¼µå­ãƒã‚§ãƒƒã‚¯
            if file_path.suffix.lower() not in self.supported_extensions:
                continue
            
            try:
                # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±å–å¾—
                stat = file_path.stat()
                if stat.st_size > 1024 * 1024:  # 1MBä»¥ä¸Šã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¹ã‚­ãƒƒãƒ—
                    rich_ui.print_message(f"âš ï¸  å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¹ã‚­ãƒƒãƒ—: {file_path} ({stat.st_size} bytes)", "warning")
                    continue
                
                # ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹èª­ã¿è¾¼ã¿
                try:
                    content = file_path.read_text(encoding='utf-8')
                except UnicodeDecodeError:
                    # UTF-8ã§èª­ã‚ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                    continue
                
                # CodeDocumentã‚’ä½œæˆ
                language = self.supported_extensions[file_path.suffix.lower()]
                modified_time = datetime.fromtimestamp(stat.st_mtime)
                
                relative_path = file_path.relative_to(self.project_path)
                
                code_doc = CodeDocument(
                    file_path=str(relative_path),
                    content=content,
                    language=language,
                    size=stat.st_size,
                    modified_time=modified_time
                )
                
                code_docs.append(code_doc)
                scanned_files += 1
                
                # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹è¡¨ç¤º
                if scanned_files % 10 == 0:
                    rich_ui.print_message(f"ğŸ“„ {scanned_files} ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¹ã‚­ãƒ£ãƒ³æ¸ˆã¿...", "muted")
                
            except Exception as e:
                rich_ui.print_message(f"âš ï¸  {file_path} ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}", "warning")
                continue
        
        rich_ui.print_success(f"âœ… ã‚¹ã‚­ãƒ£ãƒ³å®Œäº†: {len(code_docs)} ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç™ºè¦‹")
        return code_docs
    
    def create_index(self, force_rebuild: bool = False) -> bool:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆ
        
        Args:
            force_rebuild: æ—¢å­˜ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å¼·åˆ¶å†æ§‹ç¯‰ã™ã‚‹ã‹
            
        Returns:
            ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆãŒæˆåŠŸã—ãŸã‹
        """
        try:
            # æ—¢å­˜ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ãƒã‚§ãƒƒã‚¯
            if not force_rebuild and self.vector_store_path.exists():
                rich_ui.print_message("ğŸ“Š æ—¢å­˜ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’èª­ã¿è¾¼ã¿ä¸­...", "info")
                self.vector_store = Chroma(
                    persist_directory=str(self.vector_store_path),
                    embedding_function=self.embeddings
                )
                collection = self.vector_store._collection
                if collection.count() > 0:
                    rich_ui.print_success(f"âœ… æ—¢å­˜ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’èª­ã¿è¾¼ã¿å®Œäº† ({collection.count()} ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ)")
                    return True
            
            # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¹ã‚­ãƒ£ãƒ³
            code_docs = self.scan_project()
            if not code_docs:
                rich_ui.print_warning("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                return False
            
            # LangChain Documents ã«å¤‰æ›
            rich_ui.print_message("ğŸ”„ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å¤‰æ›ä¸­...", "info")
            documents = []
            
            for code_doc in code_docs:
                # ã‚³ãƒ¼ãƒ‰ã‚’é©åˆ‡ãªã‚µã‚¤ã‚ºã«åˆ†å‰²
                chunks = self.text_splitter.split_text(code_doc.content)
                
                for i, chunk in enumerate(chunks):
                    metadata = {
                        "file_path": code_doc.file_path,
                        "language": code_doc.language,
                        "size": code_doc.size,
                        "modified_time": code_doc.modified_time.isoformat(),
                        "chunk_index": i,
                        "total_chunks": len(chunks)
                    }
                    
                    document = Document(
                        page_content=chunk,
                        metadata=metadata
                    )
                    documents.append(document)
            
            rich_ui.print_message(f"ğŸ“š {len(documents)} ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²å®Œäº†", "info")
            
            # ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ä½œæˆ
            rich_ui.print_message("ğŸ§  ãƒ™ã‚¯ãƒˆãƒ«åŸ‹ã‚è¾¼ã¿ã‚’ä½œæˆä¸­...", "info")
            start_time = time.time()
            
            # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæº–å‚™
            self.vector_store_path.parent.mkdir(parents=True, exist_ok=True)
            
            # ChromaDBã§ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ä½œæˆ
            self.vector_store = Chroma.from_documents(
                documents=documents,
                embedding=self.embeddings,
                persist_directory=str(self.vector_store_path)
            )
            
            # æ°¸ç¶šåŒ–
            self.vector_store.persist()
            
            elapsed = time.time() - start_time
            rich_ui.print_success(f"âœ… ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆå®Œäº† ({elapsed:.2f}ç§’)")
            rich_ui.print_message(f"ğŸ’¾ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä¿å­˜: {self.vector_store_path}", "info")
            
            return True
            
        except Exception as e:
            rich_ui.print_error(f"ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆã«å¤±æ•—: {e}")
            return False
    
    def get_index_stats(self) -> Dict[str, Any]:
        """ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®çµ±è¨ˆæƒ…å ±ã‚’å–å¾—
        
        Returns:
            ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹çµ±è¨ˆæƒ…å ±
        """
        if not self.vector_store:
            return {"status": "not_initialized"}
        
        try:
            collection = self.vector_store._collection
            count = collection.count()
            
            # ãƒ•ã‚¡ã‚¤ãƒ«æ•°ã‚’é›†è¨ˆ
            all_docs = self.vector_store.get()
            file_paths = set()
            languages = {}
            
            for metadata in all_docs.get('metadatas', []):
                if metadata:
                    file_path = metadata.get('file_path')
                    language = metadata.get('language')
                    
                    if file_path:
                        file_paths.add(file_path)
                    
                    if language:
                        languages[language] = languages.get(language, 0) + 1
            
            return {
                "status": "ready",
                "total_chunks": count,
                "unique_files": len(file_paths),
                "languages": languages,
                "index_path": str(self.vector_store_path),
                "created": self.vector_store_path.exists()
            }
            
        except Exception as e:
            return {"status": "error", "error": str(e)}
    
    def search_code(self, query: str, k: int = 5, filter_dict: Optional[Dict] = None) -> List[Dict[str, Any]]:
        """ã‚³ãƒ¼ãƒ‰ã‚’æ¤œç´¢
        
        Args:
            query: æ¤œç´¢ã‚¯ã‚¨ãƒª
            k: å–å¾—ã™ã‚‹çµæœæ•°
            filter_dict: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿
            
        Returns:
            æ¤œç´¢çµæœä¸€è¦§
        """
        if not self.vector_store:
            raise ValueError("ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        try:
            # é¡ä¼¼æ¤œç´¢å®Ÿè¡Œ
            if filter_dict:
                docs = self.vector_store.similarity_search_with_score(
                    query, k=k, filter=filter_dict
                )
            else:
                docs = self.vector_store.similarity_search_with_score(query, k=k)
            
            results = []
            for doc, score in docs:
                result = {
                    "content": doc.page_content,
                    "score": float(score),
                    "metadata": doc.metadata,
                    "file_path": doc.metadata.get("file_path", "unknown"),
                    "language": doc.metadata.get("language", "unknown"),
                    "chunk_index": doc.metadata.get("chunk_index", 0)
                }
                results.append(result)
            
            return results
            
        except Exception as e:
            rich_ui.print_error(f"ã‚³ãƒ¼ãƒ‰æ¤œç´¢ã«å¤±æ•—: {e}")
            return []
    
    def close(self) -> None:
        """ãƒªã‚½ãƒ¼ã‚¹ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        if self.vector_store:
            try:
                self.vector_store.persist()
            except Exception as e:
                rich_ui.print_warning(f"ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä¿å­˜æ™‚ã«è­¦å‘Š: {e}")
        
        self.vector_store = None