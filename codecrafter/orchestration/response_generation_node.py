"""
å¿œç­”ç”Ÿæˆãƒãƒ¼ãƒ‰ (Response Generation Node)

5ãƒãƒ¼ãƒ‰ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®æœ€çµ‚ãƒãƒ¼ãƒ‰
TaskProfileãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«åŸºã¥ã„ã¦æ±ºå®šè«–çš„ã«ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
LLMå‘¼ã³å‡ºã—ã‚’è¡Œã‚ãªã„æ©Ÿæ¢°çš„ãªå‡¦ç†ã®ã¿
"""

import re
from typing import Dict, Any, List, Optional
from datetime import datetime

from ..templates import TaskProfileType, get_template, validate_template_data
from ..state.agent_state import AgentState
from ..prompts.four_node_context import GatheredInfo, ExecutionResult
from ..ui.rich_ui import rich_ui


class ResponseGenerationNode:
    """å¿œç­”ç”Ÿæˆãƒãƒ¼ãƒ‰
    
    åé›†ã•ã‚ŒãŸå…¨æƒ…å ±ã¨TaskProfileãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‹ã‚‰
    æœ€çµ‚çš„ãªãƒ¦ãƒ¼ã‚¶ãƒ¼å‘ã‘ãƒ¬ãƒãƒ¼ãƒˆã‚’æ±ºå®šè«–çš„ã«ç”Ÿæˆ
    """
    
    def __init__(self):
        """ãƒãƒ¼ãƒ‰ã‚’åˆæœŸåŒ–"""
        self.data_extractors = self._build_data_extractors()
    
    def generate_response(self, state: AgentState) -> str:
        """æœ€çµ‚å¿œç­”ã‚’ç”Ÿæˆ
        
        Args:
            state: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆçŠ¶æ…‹ï¼ˆå…¨ã¦ã®åé›†æƒ…å ±ã‚’å«ã‚€ï¼‰
            
        Returns:
            ãƒ¦ãƒ¼ã‚¶ãƒ¼å‘ã‘ã®æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆï¼ˆMarkdownå½¢å¼ï¼‰
        """
        try:
            rich_ui.print_step("[å¿œç­”ç”Ÿæˆ] ãƒ•ã‚§ãƒ¼ã‚ºé–‹å§‹")
            
            # TaskProfileã®å–å¾—
            task_profile_type = self._extract_task_profile(state)
            if not task_profile_type:
                return self._generate_error_response("TaskProfileã®ç‰¹å®šã«å¤±æ•—ã—ã¾ã—ãŸ")
            
            rich_ui.print_message(f"TaskProfile: {task_profile_type.value}", "info")
            
            # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®å–å¾—
            template = get_template(task_profile_type)
            
            # ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
            extracted_data = self._extract_data_for_template(state, template)
            
            # ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼
            if not validate_template_data(task_profile_type, extracted_data):
                rich_ui.print_warning("å¿…é ˆãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ - ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å€¤ã‚’ä½¿ç”¨")
            
            # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«ãƒ‡ãƒ¼ã‚¿ã‚’åŸ‹ã‚è¾¼ã¿
            final_report = self._fill_template(template, extracted_data)
            
            # Markdownæ•´å½¢
            formatted_report = self._format_markdown(final_report)
            
            rich_ui.print_success("[å¿œç­”ç”Ÿæˆ] å®Œäº†")
            
            return formatted_report
            
        except Exception as e:
            rich_ui.print_error(f"å¿œç­”ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return self._generate_error_response(f"å¿œç­”ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
    
    def _extract_task_profile(self, state: AgentState) -> Optional[TaskProfileType]:
        """AgentStateã‹ã‚‰TaskProfileTypeã‚’æŠ½å‡º
        
        Args:
            state: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆçŠ¶æ…‹
            
        Returns:
            TaskProfileTypeã€å–å¾—ã§ããªã„å ´åˆã¯None
        """
        try:
            # four_node_contextã‹ã‚‰å–å¾—ã‚’è©¦è¡Œ
            if hasattr(state, 'four_node_context') and state.four_node_context:
                if hasattr(state.four_node_context, 'task_profile_type'):
                    return state.four_node_context.task_profile_type
            
            # current_taskã‹ã‚‰å–å¾—ã‚’è©¦è¡Œ
            if hasattr(state, 'current_task') and state.current_task:
                if hasattr(state.current_task, 'task_profile_type'):
                    return state.current_task.task_profile_type
            
            # conversation_historyã‹ã‚‰æ¨æ¸¬ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
            if hasattr(state, 'conversation_history') and state.conversation_history:
                last_user_message = None
                for msg in reversed(state.conversation_history):
                    if msg.role == 'user':
                        last_user_message = msg.content
                        break
                
                if last_user_message:
                    from ..services.task_classifier import task_classifier
                    classification = task_classifier.classify(last_user_message)
                    return classification.profile_type
            
            return None
            
        except Exception as e:
            rich_ui.print_warning(f"TaskProfileæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _extract_data_for_template(self, state: AgentState, template) -> Dict[str, str]:
        """ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
        
        Args:
            state: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆçŠ¶æ…‹
            template: TaskProfileTemplate
            
        Returns:
            ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå¤‰æ•°ã‚’ã‚­ãƒ¼ã¨ã—ãŸè¾æ›¸
        """
        extracted_data = {}
        
        try:
            # gathered_info ã‚’è¤‡æ•°ã®ã‚½ãƒ¼ã‚¹ã‹ã‚‰å–å¾—ã‚’è©¦è¡Œ
            gathered_info = {}
            
            # 1. collected_contextã‹ã‚‰
            if hasattr(state, 'collected_context') and state.collected_context:
                gathered_info.update(state.collected_context)
            
            # 2. gathered_info_detailed ã‹ã‚‰ï¼ˆä¿®æ­£ç‰ˆï¼‰
            if 'gathered_info_detailed' in gathered_info:
                detailed = gathered_info['gathered_info_detailed']
                if 'collected_files' in detailed:
                    gathered_info['collected_files'] = detailed['collected_files']
            
            # 3. conversation_historyã‹ã‚‰æƒ…å ±åé›†çµæœã‚’å¾©å…ƒ
            self._restore_gathered_info_from_history(state, gathered_info)
            
            print(f"[RESPONSE_DEBUG] gathered_info keys: {list(gathered_info.keys())}")
            if 'collected_files' in gathered_info:
                print(f"[RESPONSE_DEBUG] collected_files count: {len(gathered_info['collected_files'])}")
            
            # data_mappingã«åŸºã¥ã„ã¦ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
            for template_var, data_source in template.data_mapping.items():
                value = self._extract_specific_data(state, data_source, gathered_info)
                extracted_data[template_var] = value or template.fallback_values.get(template_var, "æƒ…å ±ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
                print(f"[RESPONSE_DEBUG] {template_var} = {len(str(value))}æ–‡å­—")
            
            return extracted_data
            
        except Exception as e:
            rich_ui.print_warning(f"ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å€¤ã§å…¨ã¦åŸ‹ã‚ã‚‹
            return {var: template.fallback_values.get(var, "ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼") 
                   for var in template.data_mapping.keys()}
    
    def _extract_specific_data(self, state: AgentState, data_source: str, gathered_info: Dict) -> Optional[str]:
        """ç‰¹å®šã®ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‹ã‚‰å€¤ã‚’æŠ½å‡º
        
        Args:
            state: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆçŠ¶æ…‹
            data_source: ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹å
            gathered_info: åé›†æ¸ˆã¿æƒ…å ±
            
        Returns:
            æŠ½å‡ºã•ã‚ŒãŸå€¤ã€å–å¾—ã§ããªã„å ´åˆã¯None
        """
        try:
            extractor = self.data_extractors.get(data_source)
            if extractor:
                return extractor(state, gathered_info)
            
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: gathered_infoã‹ã‚‰ç›´æ¥å–å¾—ã‚’è©¦è¡Œ
            return gathered_info.get(data_source)
            
        except Exception as e:
            rich_ui.print_warning(f"ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚¨ãƒ©ãƒ¼ ({data_source}): {e}")
            return None
    
    def _restore_gathered_info_from_history(self, state: AgentState, gathered_info: Dict) -> None:
        """å¯¾è©±å±¥æ­´ã‹ã‚‰åé›†æƒ…å ±ã‚’å¾©å…ƒ"""
        try:
            # æœ€è¿‘ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰æƒ…å ±åé›†ã®ç—•è·¡ã‚’æ¢ã™
            if hasattr(state, 'conversation_history'):
                for msg in reversed(state.conversation_history[-10:]):  # ç›´è¿‘10ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
                    if msg.role == 'assistant' and '[OK] ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿å–ã‚Šå®Œäº†:' in msg.content:
                        # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿å–ã‚ŠæˆåŠŸã®ç—•è·¡ã‹ã‚‰æ¨æ¸¬...ï¼ˆç°¡æ˜“å®Ÿè£…ï¼‰
                        pass
        except Exception as e:
            print(f"[RESPONSE_DEBUG] å±¥æ­´å¾©å…ƒã‚¨ãƒ©ãƒ¼: {e}")
    
    def _build_data_extractors(self) -> Dict[str, Any]:
        """ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºé–¢æ•°ã®è¾æ›¸ã‚’æ§‹ç¯‰
        
        Returns:
            ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹åã‚’ã‚­ãƒ¼ã¨ã—ãŸæŠ½å‡ºé–¢æ•°ã®è¾æ›¸
        """
        return {
            "target_filename": self._extract_target_filename,
            "file_content_analysis": self._extract_file_content_analysis,
            "file_metadata_summary": self._extract_file_metadata_summary,
            "dependencies_summary": self._extract_dependencies_summary,
            "usage_examples": self._extract_usage_examples,
            "analysis_target": self._extract_analysis_target,
            "quality_metrics": self._extract_quality_metrics,
            "identified_issues": self._extract_identified_issues,
            "improvement_suggestions": self._extract_improvement_suggestions,
            "risk_priority_summary": self._extract_risk_priority_summary,
            "target_name": self._extract_target_name,
            "creation_approach": self._extract_creation_approach,
            "implementation_details": self._extract_implementation_details,
            "risk_considerations": self._extract_risk_considerations,
            "follow_up_actions": self._extract_follow_up_actions,
            "modification_target": self._extract_modification_target,
            "affected_files_list": self._extract_affected_files_list,
            "modification_details": self._extract_modification_details,
            "change_impact_summary": self._extract_change_impact_summary,
            "backup_and_safety_info": self._extract_backup_and_safety_info,
            "search_term": self._extract_search_term,
            "discovered_files_list": self._extract_discovered_files_list,
            "code_snippets": self._extract_code_snippets,
            "search_statistics": self._extract_search_statistics,
            "additional_findings": self._extract_additional_findings,
            "guidance_topic": self._extract_guidance_topic,
            "requirement_list": self._extract_requirement_list,
            "step_by_step_guide": self._extract_step_by_step_guide,
            "troubleshooting_info": self._extract_troubleshooting_info,
            "best_practices": self._extract_best_practices
        }
    
    # ===== ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºãƒ¡ã‚½ãƒƒãƒ‰ç¾¤ =====
    
    def _extract_target_filename(self, state: AgentState, gathered_info: Dict) -> str:
        """å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æŠ½å‡º"""
        # collected_filesã‹ã‚‰æœ€åˆã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å–å¾—
        if 'collected_files' in gathered_info and gathered_info['collected_files']:
            file_paths = list(gathered_info['collected_files'].keys())
            if file_paths:
                # ãƒ‘ã‚¹ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«åã®ã¿ã‚’æŠ½å‡º
                import os
                return os.path.basename(file_paths[0])
        
        # conversation_historyã‹ã‚‰æ¨æ¸¬
        if hasattr(state, 'conversation_history') and state.conversation_history:
            for msg in reversed(state.conversation_history):
                if msg.role == 'user':
                    # ãƒ•ã‚¡ã‚¤ãƒ«åã‚‰ã—ããƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢
                    import re
                    file_pattern = r'([a-zA-Z_][a-zA-Z0-9_]*\.[a-zA-Z]{1,4})'
                    matches = re.findall(file_pattern, msg.content)
                    if matches:
                        return matches[0]
        
        return "ç‰¹å®šã®ãƒ•ã‚¡ã‚¤ãƒ«"
    
    def _extract_file_content_analysis(self, state: AgentState, gathered_info: Dict) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã®åˆ†æã‚’æŠ½å‡ºï¼ˆè©³ç´°ãªã‚³ãƒ¼ãƒ‰å†…å®¹ã‚’å«ã‚€ï¼‰"""
        if 'collected_files' in gathered_info and gathered_info['collected_files']:
            files_info = gathered_info['collected_files']
            
            analysis_parts = []
            for file_path, file_content in files_info.items():
                if hasattr(file_content, 'content'):
                    content = file_content.content
                else:
                    content = str(file_content)
                
                # åŸºæœ¬æƒ…å ±ã®åˆ†æ
                lines_count = len(content.split('\n'))
                chars_count = len(content)
                
                # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆtest_step2d_graphãªã©ï¼‰ã¯è©³ç´°ã«åˆ†æ
                is_target_file = any(pattern in file_path.lower() for pattern in ['test_step2d_graph', 'target', 'main'])
                
                if is_target_file and file_path.endswith('.py'):
                    # Pythonè©³ç´°åˆ†æ
                    import_matches = re.findall(r'^(?:import\s+(\w+)|from\s+([\w.]+)\s+import)', content, re.MULTILINE)
                    imports = [m[0] or m[1] for m in import_matches]
                    
                    class_matches = re.findall(r'^class\s+(\w+)', content, re.MULTILINE)
                    function_matches = re.findall(r'^(?:def|async def)\s+(\w+)', content, re.MULTILINE)
                    
                    analysis_parts.append(f"""## {file_path}

### ğŸ“Š ãƒ•ã‚¡ã‚¤ãƒ«æ¦‚è¦
- **è¡Œæ•°**: {lines_count}è¡Œ
- **æ–‡å­—æ•°**: {chars_count:,}æ–‡å­—  
- **ã‚¤ãƒ³ãƒãƒ¼ãƒˆ**: {len(imports)}å€‹
- **ã‚¯ãƒ©ã‚¹**: {len(class_matches)}å€‹
- **é–¢æ•°**: {len(function_matches)}å€‹

### ğŸ“¦ ã‚¤ãƒ³ãƒãƒ¼ãƒˆä¸€è¦§
{chr(10).join([f"- `{imp}`" for imp in imports[:10]]) if imports else "- ãªã—"}

### ğŸ—ï¸ ã‚¯ãƒ©ã‚¹ä¸€è¦§  
{chr(10).join([f"- `{cls}`" for cls in class_matches]) if class_matches else "- ãªã—"}

### âš™ï¸ é–¢æ•°ä¸€è¦§
{chr(10).join([f"- `{func}()`" for func in function_matches]) if function_matches else "- ãªã—"}

### ğŸ“ ã‚³ãƒ¼ãƒ‰å†…å®¹
```python
{content[:3000]}{'...[æ®‹ã‚Š' + str(max(0, len(content) - 3000)) + 'æ–‡å­—]' if len(content) > 3000 else ''}
```""")
                
                elif file_path.endswith('.py'):
                    # é€šå¸¸ã®Pythonãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆç°¡æ˜“ç‰ˆï¼‰
                    import_count = len(re.findall(r'^import\s+|^from\s+', content, re.MULTILINE))
                    class_count = len(re.findall(r'^class\s+\w+', content, re.MULTILINE))
                    function_count = len(re.findall(r'^def\s+\w+', content, re.MULTILINE))
                    
                    analysis_parts.append(f"""**{file_path}**
- è¡Œæ•°: {lines_count}è¡Œ
- æ–‡å­—æ•°: {chars_count}æ–‡å­—  
- ã‚¤ãƒ³ãƒãƒ¼ãƒˆ: {import_count}å€‹
- ã‚¯ãƒ©ã‚¹: {class_count}å€‹
- é–¢æ•°: {function_count}å€‹

```python
{content[:500]}{'...[çœç•¥]' if len(content) > 500 else ''}
```""")
                else:
                    # éPythonãƒ•ã‚¡ã‚¤ãƒ«
                    analysis_parts.append(f"""**{file_path}**
- è¡Œæ•°: {lines_count}è¡Œ
- æ–‡å­—æ•°: {chars_count}æ–‡å­—""")
            
            return "\n\n".join(analysis_parts)
        
        return "ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã®åˆ†æãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“"
    
    def _extract_file_metadata_summary(self, state: AgentState, gathered_info: Dict) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®è¦ç´„ã‚’æŠ½å‡º"""
        if 'collected_files' in gathered_info and gathered_info['collected_files']:
            files_info = gathered_info['collected_files']
            
            metadata_parts = []
            for file_path, file_content in files_info.items():
                # ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ã‹ã‚‰ç¨®åˆ¥ã‚’åˆ¤å®š
                import os
                _, ext = os.path.splitext(file_path)
                file_type = self._get_file_type_description(ext)
                
                # ã‚µã‚¤ã‚ºæƒ…å ±
                if hasattr(file_content, 'size'):
                    size_info = f"{file_content.size} bytes"
                else:
                    size_info = "ã‚µã‚¤ã‚ºä¸æ˜"
                
                metadata_parts.append(f"- **{os.path.basename(file_path)}**: {file_type} ({size_info})")
            
            return "\n".join(metadata_parts)
        
        return "ãƒ•ã‚¡ã‚¤ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“"
    
    def _get_file_type_description(self, ext: str) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ã‹ã‚‰ç¨®åˆ¥èª¬æ˜ã‚’å–å¾—"""
        type_map = {
            '.py': 'Pythonã‚¹ã‚¯ãƒªãƒ—ãƒˆ',
            '.js': 'JavaScriptãƒ•ã‚¡ã‚¤ãƒ«',
            '.ts': 'TypeScriptãƒ•ã‚¡ã‚¤ãƒ«',
            '.md': 'Markdownãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ',
            '.json': 'JSONè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«',
            '.yaml': 'YAMLè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«',
            '.yml': 'YAMLè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«',
            '.txt': 'ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«',
            '.html': 'HTMLãƒ•ã‚¡ã‚¤ãƒ«',
            '.css': 'CSSã‚¹ã‚¿ã‚¤ãƒ«ã‚·ãƒ¼ãƒˆ'
        }
        return type_map.get(ext.lower(), 'ãƒ•ã‚¡ã‚¤ãƒ«')
    
    # ä»–ã®ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºãƒ¡ã‚½ãƒƒãƒ‰ã¯ç°¡ç•¥å®Ÿè£…ï¼ˆå¿…è¦ã«å¿œã˜ã¦æ‹¡å¼µï¼‰
    def _extract_dependencies_summary(self, state: AgentState, gathered_info: Dict) -> str:
        return "ä¾å­˜é–¢ä¿‚ã®åˆ†æã¯ç¾åœ¨å®Ÿè£…ä¸­ã§ã™"
    
    def _extract_usage_examples(self, state: AgentState, gathered_info: Dict) -> str:
        return "ä½¿ç”¨ä¾‹ã®ç”Ÿæˆã¯ç¾åœ¨å®Ÿè£…ä¸­ã§ã™"
    
    def _extract_analysis_target(self, state: AgentState, gathered_info: Dict) -> str:
        return self._extract_target_filename(state, gathered_info)
    
    def _extract_quality_metrics(self, state: AgentState, gathered_info: Dict) -> str:
        return "å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®åˆ†æã¯ç¾åœ¨å®Ÿè£…ä¸­ã§ã™"
    
    def _extract_identified_issues(self, state: AgentState, gathered_info: Dict) -> str:
        return "å•é¡Œã®ç‰¹å®šã¯ç¾åœ¨å®Ÿè£…ä¸­ã§ã™"
    
    def _extract_improvement_suggestions(self, state: AgentState, gathered_info: Dict) -> str:
        return "æ”¹å–„ææ¡ˆã®ç”Ÿæˆã¯ç¾åœ¨å®Ÿè£…ä¸­ã§ã™"
    
    def _extract_risk_priority_summary(self, state: AgentState, gathered_info: Dict) -> str:
        return "ãƒªã‚¹ã‚¯å„ªå…ˆåº¦ã®è©•ä¾¡ã¯ç¾åœ¨å®Ÿè£…ä¸­ã§ã™"
    
    def _extract_target_name(self, state: AgentState, gathered_info: Dict) -> str:
        return self._extract_target_filename(state, gathered_info)
    
    def _extract_creation_approach(self, state: AgentState, gathered_info: Dict) -> str:
        return "ä½œæˆã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®æ±ºå®šã¯ç¾åœ¨å®Ÿè£…ä¸­ã§ã™"
    
    def _extract_implementation_details(self, state: AgentState, gathered_info: Dict) -> str:
        return "å®Ÿè£…è©³ç´°ã®ç”Ÿæˆã¯ç¾åœ¨å®Ÿè£…ä¸­ã§ã™"
    
    def _extract_risk_considerations(self, state: AgentState, gathered_info: Dict) -> str:
        return "ãƒªã‚¹ã‚¯è€ƒæ…®äº‹é …ã®åˆ†æã¯ç¾åœ¨å®Ÿè£…ä¸­ã§ã™"
    
    def _extract_follow_up_actions(self, state: AgentState, gathered_info: Dict) -> str:
        return "ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ææ¡ˆã¯ç¾åœ¨å®Ÿè£…ä¸­ã§ã™"
    
    def _extract_modification_target(self, state: AgentState, gathered_info: Dict) -> str:
        return self._extract_target_filename(state, gathered_info)
    
    def _extract_affected_files_list(self, state: AgentState, gathered_info: Dict) -> str:
        return "å½±éŸ¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ç‰¹å®šã¯ç¾åœ¨å®Ÿè£…ä¸­ã§ã™"
    
    def _extract_modification_details(self, state: AgentState, gathered_info: Dict) -> str:
        return "å¤‰æ›´è©³ç´°ã®åˆ†æã¯ç¾åœ¨å®Ÿè£…ä¸­ã§ã™"
    
    def _extract_change_impact_summary(self, state: AgentState, gathered_info: Dict) -> str:
        return "å¤‰æ›´å½±éŸ¿ã®åˆ†æã¯ç¾åœ¨å®Ÿè£…ä¸­ã§ã™"
    
    def _extract_backup_and_safety_info(self, state: AgentState, gathered_info: Dict) -> str:
        return "ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¨å®‰å…¨å¯¾ç­–ã®æƒ…å ±ã¯ç¾åœ¨å®Ÿè£…ä¸­ã§ã™"
    
    def _extract_search_term(self, state: AgentState, gathered_info: Dict) -> str:
        return "æ¤œç´¢ã‚¯ã‚¨ãƒªã®æŠ½å‡ºã¯ç¾åœ¨å®Ÿè£…ä¸­ã§ã™"
    
    def _extract_discovered_files_list(self, state: AgentState, gathered_info: Dict) -> str:
        return "ç™ºè¦‹ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¹ãƒˆç”Ÿæˆã¯ç¾åœ¨å®Ÿè£…ä¸­ã§ã™"
    
    def _extract_code_snippets(self, state: AgentState, gathered_info: Dict) -> str:
        return "ã‚³ãƒ¼ãƒ‰ã‚¹ãƒ‹ãƒšãƒƒãƒˆã®æŠ½å‡ºã¯ç¾åœ¨å®Ÿè£…ä¸­ã§ã™"
    
    def _extract_search_statistics(self, state: AgentState, gathered_info: Dict) -> str:
        return "æ¤œç´¢çµ±è¨ˆã®ç”Ÿæˆã¯ç¾åœ¨å®Ÿè£…ä¸­ã§ã™"
    
    def _extract_additional_findings(self, state: AgentState, gathered_info: Dict) -> str:
        return "è¿½åŠ ç™ºè¦‹äº‹é …ã¯ç¾åœ¨å®Ÿè£…ä¸­ã§ã™"
    
    def _extract_guidance_topic(self, state: AgentState, gathered_info: Dict) -> str:
        return "ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ãƒˆãƒ”ãƒƒã‚¯ã®æŠ½å‡ºã¯ç¾åœ¨å®Ÿè£…ä¸­ã§ã™"
    
    def _extract_requirement_list(self, state: AgentState, gathered_info: Dict) -> str:
        return "å‰ææ¡ä»¶ã®æŠ½å‡ºã¯ç¾åœ¨å®Ÿè£…ä¸­ã§ã™"
    
    def _extract_step_by_step_guide(self, state: AgentState, gathered_info: Dict) -> str:
        return "ã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—ã‚¬ã‚¤ãƒ‰ã®ç”Ÿæˆã¯ç¾åœ¨å®Ÿè£…ä¸­ã§ã™"
    
    def _extract_troubleshooting_info(self, state: AgentState, gathered_info: Dict) -> str:
        return "ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°æƒ…å ±ã¯ç¾åœ¨å®Ÿè£…ä¸­ã§ã™"
    
    def _extract_best_practices(self, state: AgentState, gathered_info: Dict) -> str:
        return "ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã®ææ¡ˆã¯ç¾åœ¨å®Ÿè£…ä¸­ã§ã™"
    
    def _fill_template(self, template, data: Dict[str, str]) -> str:
        """ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«ãƒ‡ãƒ¼ã‚¿ã‚’åŸ‹ã‚è¾¼ã¿
        
        Args:
            template: TaskProfileTemplate
            data: åŸ‹ã‚è¾¼ã‚€ãƒ‡ãƒ¼ã‚¿ã®è¾æ›¸
            
        Returns:
            ãƒ‡ãƒ¼ã‚¿ãŒåŸ‹ã‚è¾¼ã¾ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
        """
        result = template.structure
        
        for placeholder, value in data.items():
            pattern = "{" + placeholder + "}"
            result = result.replace(pattern, str(value))
        
        return result
    
    def _format_markdown(self, content: str) -> str:
        """Markdownã®æ•´å½¢
        
        Args:
            content: æ•´å½¢å‰ã®Markdown
            
        Returns:
            æ•´å½¢å¾Œã®Markdown
        """
        # ç©ºè¡Œã®çµ±ä¸€
        content = re.sub(r'\n{3,}', '\n\n', content)
        
        # å…ˆé ­ã¨æœ«å°¾ã®ç©ºç™½ã‚’é™¤å»
        content = content.strip()
        
        # ç”Ÿæˆæ—¥æ™‚ã‚’è¿½åŠ 
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        footer = f"\n\n---\n*Generated by Duckflow at {timestamp}*"
        
        return content + footer
    
    def _generate_error_response(self, error_message: str) -> str:
        """ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¿œç­”ã‚’ç”Ÿæˆ
        
        Args:
            error_message: ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            
        Returns:
            ã‚¨ãƒ©ãƒ¼å¿œç­”ã®Markdown
        """
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        return f"""## âŒ å‡¦ç†ã‚¨ãƒ©ãƒ¼

ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚

### ã‚¨ãƒ©ãƒ¼è©³ç´°
{error_message}

### å¯¾å‡¦æ–¹æ³•
1. è¦æ±‚ã‚’å†åº¦ç¢ºèªã—ã¦ãã ã•ã„
2. å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„  
3. ã‚¨ãƒ©ãƒ¼ãŒç¶™ç¶šã™ã‚‹å ´åˆã¯ã€ã‚ˆã‚Šå…·ä½“çš„ãªæŒ‡ç¤ºã‚’ãŠè©¦ã—ãã ã•ã„

---
*Generated by Duckflow at {timestamp}*"""


# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
response_generator = ResponseGenerationNode()