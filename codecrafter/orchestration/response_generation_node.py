"""
å¿œç­”ç”Ÿæˆãƒãƒ¼ãƒ‰ (Response Generation Node)

5ãƒãƒ¼ãƒ‰ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®æœ€çµ‚ãƒãƒ¼ãƒ‰
TaskProfileãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«åŸºã¥ã„ã¦æ±ºå®šè«–çš„ã«ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
LLMå‘¼ã³å‡ºã—ã‚’è¡Œã‚ãªã„æ©Ÿæ¢°çš„ãªå‡¦ç†ã®ã¿
"""

import re
from typing import Dict, Any, List, Optional
from datetime import datetime
from dataclasses import dataclass

from ..templates import TaskProfileType, get_template, validate_template_data
from ..state.agent_state import AgentState
from ..prompts.four_node_context import GatheredInfo, ExecutionResult
from ..ui.rich_ui import rich_ui


@dataclass
class ResponseResult:
    """å¿œç­”ç”Ÿæˆçµæœ"""
    final_response: str
    template_used: str
    data_completeness: float
    generation_method: str = "deterministic"


class ResponseGenerationNode:
    """å¿œç­”ç”Ÿæˆãƒãƒ¼ãƒ‰
    
    åé›†ã•ã‚ŒãŸå…¨æƒ…å ±ã¨TaskProfileãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‹ã‚‰
    æœ€çµ‚çš„ãªãƒ¦ãƒ¼ã‚¶ãƒ¼å‘ã‘ãƒ¬ãƒãƒ¼ãƒˆã‚’æ±ºå®šè«–çš„ã«ç”Ÿæˆ
    """
    
    def __init__(self):
        """ãƒãƒ¼ãƒ‰ã‚’åˆæœŸåŒ–"""
        self.data_extractors = self._build_data_extractors()
    
    def generate_response(
        self, 
        state: AgentState, 
        gathered_info: Optional[GatheredInfo] = None, 
        execution_result: Optional[ExecutionResult] = None, 
        task_profile_type: Optional[TaskProfileType] = None
    ) -> ResponseResult:
        """æœ€çµ‚å¿œç­”ã‚’ç”Ÿæˆ (5ãƒãƒ¼ãƒ‰ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å¯¾å¿œ)
        
        Args:
            state: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆçŠ¶æ…‹
            gathered_info: æƒ…å ±åé›†çµæœ (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
            execution_result: å®Ÿè¡Œçµæœ (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
            task_profile_type: TaskProfileåˆ†é¡ (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
            
        Returns:
            å¿œç­”ç”Ÿæˆçµæœã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        """
        try:
            rich_ui.print_step("[å¿œç­”ç”Ÿæˆ] ãƒ•ã‚§ãƒ¼ã‚ºé–‹å§‹")
            
            # TaskProfileã®å–å¾— (ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å„ªå…ˆã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†)
            if not task_profile_type:
                task_profile_type = self._extract_task_profile(state)
            if not task_profile_type:
                error_response = self._generate_error_response("TaskProfileã®ç‰¹å®šã«å¤±æ•—ã—ã¾ã—ãŸ")
                return ResponseResult(
                    final_response=error_response,
                    template_used="error_template",
                    data_completeness=0.0
                )
            
            rich_ui.print_message(f"TaskProfile: {task_profile_type.value}", "info")
            
            # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®å–å¾—
            template = get_template(task_profile_type)
            
            # ãƒ‡ãƒ¼ã‚¿æŠ½å‡º (æ¸¡ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ´»ç”¨)
            extracted_data = self._extract_data_for_template(state, template, gathered_info, execution_result)
            
            # ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼
            data_completeness = 1.0 if validate_template_data(task_profile_type, extracted_data) else 0.6
            if data_completeness < 1.0:
                rich_ui.print_warning("å¿…é ˆãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ - ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å€¤ã‚’ä½¿ç”¨")
            
            # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«ãƒ‡ãƒ¼ã‚¿ã‚’åŸ‹ã‚è¾¼ã¿
            final_report = self._fill_template(template, extracted_data)
            
            # Markdownæ•´å½¢
            formatted_report = self._format_markdown(final_report)
            
            rich_ui.print_success("[å¿œç­”ç”Ÿæˆ] å®Œäº†")
            
            return ResponseResult(
                final_response=formatted_report,
                template_used=task_profile_type.value,
                data_completeness=data_completeness
            )
            
        except Exception as e:
            rich_ui.print_error(f"å¿œç­”ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            error_response = self._generate_error_response(f"å¿œç­”ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            return ResponseResult(
                final_response=error_response,
                template_used="error_template",
                data_completeness=0.0,
                generation_method="error_fallback"
            )
    
    def _extract_task_profile(self, state: AgentState) -> Optional[TaskProfileType]:
        """AgentStateã‹ã‚‰TaskProfileTypeã‚’æŠ½å‡º
        
        Args:
            state: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆçŠ¶æ…‹
            
        Returns:
            TaskProfileTypeã€å–å¾—ã§ããªã„å ´åˆã¯None
        """
        try:
            # four_node_contextã‹ã‚‰å–å¾—ã‚’è©¦è¡Œ
            if hasattr(state, 'four_node_context') and state.four_node_context:
                if hasattr(state.four_node_context, 'task_profile_type'):
                    return state.four_node_context.task_profile_type
            
            # current_taskã‹ã‚‰å–å¾—ã‚’è©¦è¡Œ
            if hasattr(state, 'current_task') and state.current_task:
                if hasattr(state.current_task, 'task_profile_type'):
                    return state.current_task.task_profile_type
            
            # conversation_historyã‹ã‚‰æ¨æ¸¬ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
            if hasattr(state, 'conversation_history') and state.conversation_history:
                last_user_message = None
                for msg in reversed(state.conversation_history):
                    if msg.role == 'user':
                        last_user_message = msg.content
                        break
                
                if last_user_message:
                    from ..services.task_classifier import task_classifier
                    classification = task_classifier.classify(last_user_message)
                    return classification.profile_type
            
            return None
            
        except Exception as e:
            rich_ui.print_warning(f"TaskProfileæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _extract_data_for_template(
        self, 
        state: AgentState, 
        template, 
        gathered_info: Optional[GatheredInfo] = None, 
        execution_result: Optional[ExecutionResult] = None
    ) -> Dict[str, str]:
        """ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º (5ãƒãƒ¼ãƒ‰ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å¯¾å¿œ)
        
        Args:
            state: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆçŠ¶æ…‹
            template: TaskProfileTemplate
            gathered_info: æƒ…å ±åé›†çµæœ (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
            execution_result: å®Ÿè¡Œçµæœ (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
            
        Returns:
            ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå¤‰æ•°ã‚’ã‚­ãƒ¼ã¨ã—ãŸè¾æ›¸
        """
        extracted_data = {}
        
        try:
            # gathered_info ã‚’è¤‡æ•°ã®ã‚½ãƒ¼ã‚¹ã‹ã‚‰å–å¾—ã‚’è©¦è¡Œ (ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å„ªå…ˆ)
            consolidated_gathered_info = {}
            
            # 1. ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‹ã‚‰æ¸¡ã•ã‚ŒãŸgathered_infoã‚’å„ªå…ˆ
            if gathered_info and hasattr(gathered_info, 'collected_files'):
                consolidated_gathered_info['collected_files'] = gathered_info.collected_files
                print(f"[RESPONSE_DEBUG] ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‹ã‚‰gathered_infoå–å¾—: {len(gathered_info.collected_files)}ãƒ•ã‚¡ã‚¤ãƒ«")
            
            # 2. collected_contextã‹ã‚‰ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            if hasattr(state, 'collected_context') and state.collected_context:
                context = state.collected_context
                print(f"[RESPONSE_DEBUG] collected_context keys: {list(context.keys())}")
                
                # gathered_infoã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ç›´æ¥å–å¾—
                if 'gathered_info' in context:
                    gathered_obj = context['gathered_info']
                    if hasattr(gathered_obj, 'collected_files'):
                        consolidated_gathered_info['collected_files'] = gathered_obj.collected_files
                        print(f"[RESPONSE_DEBUG] collected_contextã‹ã‚‰gathered_infoå–å¾—: {len(gathered_obj.collected_files)}ãƒ•ã‚¡ã‚¤ãƒ«")
                
                # ãã®ä»–ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚‚çµ±åˆ
                consolidated_gathered_info.update(context)
            
            # 3. gathered_info_detailed ã‹ã‚‰ï¼ˆä¿®æ­£ç‰ˆï¼‰
            if 'gathered_info_detailed' in consolidated_gathered_info:
                detailed = consolidated_gathered_info['gathered_info_detailed']
                if 'collected_files' in detailed:
                    consolidated_gathered_info['collected_files'] = detailed['collected_files']
                    print(f"[RESPONSE_DEBUG] gathered_info_detailedã‹ã‚‰å–å¾—")
            
            # 4. conversation_historyã‹ã‚‰æƒ…å ±åé›†çµæœã‚’å¾©å…ƒ
            self._restore_gathered_info_from_history(state, consolidated_gathered_info)
            
            print(f"[RESPONSE_DEBUG] consolidated_gathered_info keys: {list(consolidated_gathered_info.keys())}")
            if 'collected_files' in consolidated_gathered_info:
                print(f"[RESPONSE_DEBUG] collected_files count: {len(consolidated_gathered_info['collected_files'])}")
            
            # data_mappingã«åŸºã¥ã„ã¦ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
            for template_var, data_source in template.data_mapping.items():
                value = self._extract_specific_data(state, data_source, consolidated_gathered_info)
                extracted_data[template_var] = value or template.fallback_values.get(template_var, "æƒ…å ±ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
                print(f"[RESPONSE_DEBUG] {template_var} = {len(str(value))}æ–‡å­—")
            
            # ã€è¿½åŠ ã€‘The Pecking Orderæƒ…å ±ã‚’çµ±åˆ
            self._integrate_pecking_order_info(state, extracted_data)
            
            return extracted_data
            
        except Exception as e:
            rich_ui.print_warning(f"ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å€¤ã§å…¨ã¦åŸ‹ã‚ã‚‹
            return {var: template.fallback_values.get(var, "ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼") 
                   for var in template.data_mapping.keys()}
    
    def _extract_specific_data(self, state: AgentState, data_source: str, gathered_info: Dict) -> Optional[str]:
        """ç‰¹å®šã®ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‹ã‚‰å€¤ã‚’æŠ½å‡º
        
        Args:
            state: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆçŠ¶æ…‹
            data_source: ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹å
            gathered_info: åé›†æ¸ˆã¿æƒ…å ±
            
        Returns:
            æŠ½å‡ºã•ã‚ŒãŸå€¤ã€å–å¾—ã§ããªã„å ´åˆã¯None
        """
        try:
            extractor = self.data_extractors.get(data_source)
            if extractor:
                return extractor(state, gathered_info)
            
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: gathered_infoã‹ã‚‰ç›´æ¥å–å¾—ã‚’è©¦è¡Œ
            return gathered_info.get(data_source)
            
        except Exception as e:
            rich_ui.print_warning(f"ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚¨ãƒ©ãƒ¼ ({data_source}): {e}")
            return None
    
    def _restore_gathered_info_from_history(self, state: AgentState, gathered_info: Dict) -> None:
        """å¯¾è©±å±¥æ­´ã‹ã‚‰åé›†æƒ…å ±ã‚’å¾©å…ƒ"""
        try:
            # æœ€è¿‘ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰æƒ…å ±åé›†ã®ç—•è·¡ã‚’æ¢ã™
            if hasattr(state, 'conversation_history'):
                for msg in reversed(state.conversation_history[-10:]):  # ç›´è¿‘10ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
                    if msg.role == 'assistant' and '[OK] ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿å–ã‚Šå®Œäº†:' in msg.content:
                        # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿å–ã‚ŠæˆåŠŸã®ç—•è·¡ã‹ã‚‰æ¨æ¸¬...ï¼ˆç°¡æ˜“å®Ÿè£…ï¼‰
                        pass
        except Exception as e:
            print(f"[RESPONSE_DEBUG] å±¥æ­´å¾©å…ƒã‚¨ãƒ©ãƒ¼: {e}")
    
    def _build_data_extractors(self) -> Dict[str, Any]:
        """ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºé–¢æ•°ã®è¾æ›¸ã‚’æ§‹ç¯‰
        
        Returns:
            ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹åã‚’ã‚­ãƒ¼ã¨ã—ãŸæŠ½å‡ºé–¢æ•°ã®è¾æ›¸
        """
        return {
            "target_filename": self._extract_target_filename,
            "file_content_analysis": self._extract_file_content_analysis,
            "file_metadata_summary": self._extract_file_metadata_summary,
            "dependencies_summary": self._extract_dependencies_summary,
            "usage_examples": self._extract_usage_examples,
            "analysis_target": self._extract_analysis_target,
            "quality_metrics": self._extract_quality_metrics,
            "identified_issues": self._extract_identified_issues,
            "improvement_suggestions": self._extract_improvement_suggestions,
            "risk_priority_summary": self._extract_risk_priority_summary,
            "target_name": self._extract_target_name,
            "creation_approach": self._extract_creation_approach,
            "implementation_details": self._extract_implementation_details,
            "risk_considerations": self._extract_risk_considerations,
            "follow_up_actions": self._extract_follow_up_actions,
            "modification_target": self._extract_modification_target,
            "affected_files_list": self._extract_affected_files_list,
            "modification_details": self._extract_modification_details,
            "change_impact_summary": self._extract_change_impact_summary,
            "backup_and_safety_info": self._extract_backup_and_safety_info,
            "search_term": self._extract_search_term,
            "discovered_files_list": self._extract_discovered_files_list,
            "code_snippets": self._extract_code_snippets,
            "search_statistics": self._extract_search_statistics,
            "additional_findings": self._extract_additional_findings,
            "guidance_topic": self._extract_guidance_topic,
            "requirement_list": self._extract_requirement_list,
            "step_by_step_guide": self._extract_step_by_step_guide,
            "troubleshooting_info": self._extract_troubleshooting_info,
            "best_practices": self._extract_best_practices
        }
    
    # ===== ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºãƒ¡ã‚½ãƒƒãƒ‰ç¾¤ =====
    
    def _extract_target_filename(self, state: AgentState, gathered_info: Dict) -> str:
        """å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æŠ½å‡º"""
        # collected_filesã‹ã‚‰æœ€åˆã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å–å¾—
        if 'collected_files' in gathered_info and gathered_info['collected_files']:
            file_paths = list(gathered_info['collected_files'].keys())
            if file_paths:
                # ãƒ‘ã‚¹ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«åã®ã¿ã‚’æŠ½å‡º
                import os
                return os.path.basename(file_paths[0])
        
        # conversation_historyã‹ã‚‰æ¨æ¸¬
        if hasattr(state, 'conversation_history') and state.conversation_history:
            for msg in reversed(state.conversation_history):
                if msg.role == 'user':
                    # ãƒ•ã‚¡ã‚¤ãƒ«åã‚‰ã—ããƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢
                    import re
                    file_pattern = r'([a-zA-Z_][a-zA-Z0-9_]*\.[a-zA-Z]{1,4})'
                    matches = re.findall(file_pattern, msg.content)
                    if matches:
                        return matches[0]
        
        return "ç‰¹å®šã®ãƒ•ã‚¡ã‚¤ãƒ«"
    
    def _extract_file_content_analysis(self, state: AgentState, gathered_info: Dict) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã®åˆ†æã‚’æŠ½å‡ºï¼ˆè©³ç´°ãªã‚³ãƒ¼ãƒ‰å†…å®¹ã‚’å«ã‚€ï¼‰"""
        print(f"[FILE_ANALYSIS_DEBUG] gathered_info keys: {list(gathered_info.keys())}")
        
        if 'collected_files' in gathered_info and gathered_info['collected_files']:
            files_info = gathered_info['collected_files']
            print(f"[FILE_ANALYSIS_DEBUG] collected_files type: {type(files_info)}")
            print(f"[FILE_ANALYSIS_DEBUG] collected_files count: {len(files_info)}")
            
            analysis_parts = []
            for file_path, file_content in files_info.items():
                print(f"[FILE_ANALYSIS_DEBUG] Processing file: {file_path}, type: {type(file_content)}")
                
                # ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã®å–å¾—ï¼ˆè¤‡æ•°ã®å½¢å¼ã«å¯¾å¿œï¼‰
                if hasattr(file_content, 'content'):
                    content = file_content.content
                    print(f"[FILE_ANALYSIS_DEBUG] Content from .content: {len(content)}æ–‡å­—")
                elif hasattr(file_content, 'file_content'):
                    content = file_content.file_content
                    print(f"[FILE_ANALYSIS_DEBUG] Content from .file_content: {len(content)}æ–‡å­—")
                elif isinstance(file_content, str):
                    content = file_content
                    print(f"[FILE_ANALYSIS_DEBUG] Content as string: {len(content)}æ–‡å­—")
                else:
                    content = str(file_content)
                    print(f"[FILE_ANALYSIS_DEBUG] Content as str(): {len(content)}æ–‡å­—")
                
                # ç©ºã®å†…å®¹ã‚’ã‚¹ã‚­ãƒƒãƒ—
                if not content or content.strip() == "":
                    print(f"[FILE_ANALYSIS_DEBUG] Skipping empty file: {file_path}")
                    continue
                
                # åŸºæœ¬æƒ…å ±ã®åˆ†æ
                lines_count = len(content.split('\n'))
                chars_count = len(content)
                
                # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ‹¡å¼µå­ã‚’å–å¾—
                import os
                _, ext = os.path.splitext(file_path)
                
                if ext == '.md':
                    # Markdownãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†æ
                    header_matches = re.findall(r'^#+\s+(.+)$', content, re.MULTILINE)
                    
                    analysis_parts.append(f"""## {os.path.basename(file_path)}

### ğŸ“Š ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¦‚è¦
- **è¡Œæ•°**: {lines_count}è¡Œ
- **æ–‡å­—æ•°**: {chars_count:,}æ–‡å­—
- **è¦‹å‡ºã—æ•°**: {len(header_matches)}å€‹

### ğŸ“‹ ä¸»è¦è¦‹å‡ºã—
{chr(10).join([f"- {header}" for header in header_matches[:10]]) if header_matches else "- ãªã—"}

### ğŸ“ å†…å®¹ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
```markdown
{content[:2000]}{'...[æ®‹ã‚Š' + str(max(0, len(content) - 2000)) + 'æ–‡å­—]' if len(content) > 2000 else ''}
```""")
                
                elif ext == '.py':
                    # Pythonãƒ•ã‚¡ã‚¤ãƒ«ã®è©³ç´°åˆ†æ
                    import_matches = re.findall(r'^(?:import\s+(\w+)|from\s+([\w.]+)\s+import)', content, re.MULTILINE)
                    imports = [m[0] or m[1] for m in import_matches]
                    
                    class_matches = re.findall(r'^class\s+(\w+)', content, re.MULTILINE)
                    function_matches = re.findall(r'^(?:def|async def)\s+(\w+)', content, re.MULTILINE)
                    
                    analysis_parts.append(f"""## {os.path.basename(file_path)}

### ğŸ“Š ãƒ•ã‚¡ã‚¤ãƒ«æ¦‚è¦
- **è¡Œæ•°**: {lines_count}è¡Œ
- **æ–‡å­—æ•°**: {chars_count:,}æ–‡å­—  
- **ã‚¤ãƒ³ãƒãƒ¼ãƒˆ**: {len(imports)}å€‹
- **ã‚¯ãƒ©ã‚¹**: {len(class_matches)}å€‹
- **é–¢æ•°**: {len(function_matches)}å€‹

### ğŸ“¦ ã‚¤ãƒ³ãƒãƒ¼ãƒˆä¸€è¦§
{chr(10).join([f"- `{imp}`" for imp in imports[:10]]) if imports else "- ãªã—"}

### ğŸ—ï¸ ã‚¯ãƒ©ã‚¹ä¸€è¦§  
{chr(10).join([f"- `{cls}`" for cls in class_matches]) if class_matches else "- ãªã—"}

### âš™ï¸ é–¢æ•°ä¸€è¦§
{chr(10).join([f"- `{func}()`" for func in function_matches]) if function_matches else "- ãªã—"}

### ğŸ“ ã‚³ãƒ¼ãƒ‰å†…å®¹
```python
{content[:1500]}{'...[æ®‹ã‚Š' + str(max(0, len(content) - 1500)) + 'æ–‡å­—]' if len(content) > 1500 else ''}
```""")
                
                else:
                    # ãã®ä»–ã®ãƒ•ã‚¡ã‚¤ãƒ«
                    analysis_parts.append(f"""## {os.path.basename(file_path)}

### ğŸ“Š ãƒ•ã‚¡ã‚¤ãƒ«æ¦‚è¦
- **è¡Œæ•°**: {lines_count}è¡Œ
- **æ–‡å­—æ•°**: {chars_count:,}æ–‡å­—
- **ãƒ•ã‚¡ã‚¤ãƒ«ç¨®åˆ¥**: {ext or 'ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«'}

### ğŸ“ å†…å®¹ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
```
{content[:1000]}{'...[æ®‹ã‚Š' + str(max(0, len(content) - 1000)) + 'æ–‡å­—]' if len(content) > 1000 else ''}
```""")
            
            if analysis_parts:
                return "\n\n".join(analysis_parts)
            else:
                return "ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã¯å–å¾—ã•ã‚Œã¾ã—ãŸãŒã€åˆ†æå¯èƒ½ãªå†…å®¹ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ"
        
        return "ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã®åˆ†æãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“"
    
    def _extract_file_metadata_summary(self, state: AgentState, gathered_info: Dict) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®è¦ç´„ã‚’æŠ½å‡º"""
        if 'collected_files' in gathered_info and gathered_info['collected_files']:
            files_info = gathered_info['collected_files']
            
            metadata_parts = []
            for file_path, file_content in files_info.items():
                # ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ã‹ã‚‰ç¨®åˆ¥ã‚’åˆ¤å®š
                import os
                _, ext = os.path.splitext(file_path)
                file_type = self._get_file_type_description(ext)
                
                # ã‚µã‚¤ã‚ºæƒ…å ±
                if hasattr(file_content, 'size'):
                    size_info = f"{file_content.size} bytes"
                else:
                    size_info = "ã‚µã‚¤ã‚ºä¸æ˜"
                
                metadata_parts.append(f"- **{os.path.basename(file_path)}**: {file_type} ({size_info})")
            
            return "\n".join(metadata_parts)
        
        return "ãƒ•ã‚¡ã‚¤ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“"
    
    def _get_file_type_description(self, ext: str) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ã‹ã‚‰ç¨®åˆ¥èª¬æ˜ã‚’å–å¾—"""
        type_map = {
            '.py': 'Pythonã‚¹ã‚¯ãƒªãƒ—ãƒˆ',
            '.js': 'JavaScriptãƒ•ã‚¡ã‚¤ãƒ«',
            '.ts': 'TypeScriptãƒ•ã‚¡ã‚¤ãƒ«',
            '.md': 'Markdownãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ',
            '.json': 'JSONè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«',
            '.yaml': 'YAMLè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«',
            '.yml': 'YAMLè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«',
            '.txt': 'ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«',
            '.html': 'HTMLãƒ•ã‚¡ã‚¤ãƒ«',
            '.css': 'CSSã‚¹ã‚¿ã‚¤ãƒ«ã‚·ãƒ¼ãƒˆ'
        }
        return type_map.get(ext.lower(), 'ãƒ•ã‚¡ã‚¤ãƒ«')
    
    # ä»–ã®ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºãƒ¡ã‚½ãƒƒãƒ‰ã¯ç°¡ç•¥å®Ÿè£…ï¼ˆå¿…è¦ã«å¿œã˜ã¦æ‹¡å¼µï¼‰
    def _extract_dependencies_summary(self, state: AgentState, gathered_info: Dict) -> str:
        return "ä¾å­˜é–¢ä¿‚ã®åˆ†æã¯ç¾åœ¨å®Ÿè£…ä¸­ã§ã™"
    
    def _extract_usage_examples(self, state: AgentState, gathered_info: Dict) -> str:
        return "ä½¿ç”¨ä¾‹ã®ç”Ÿæˆã¯ç¾åœ¨å®Ÿè£…ä¸­ã§ã™"
    
    def _extract_analysis_target(self, state: AgentState, gathered_info: Dict) -> str:
        return self._extract_target_filename(state, gathered_info)
    
    def _extract_quality_metrics(self, state: AgentState, gathered_info: Dict) -> str:
        """å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’æŠ½å‡º"""
        if 'collected_files' in gathered_info and gathered_info['collected_files']:
            files_info = gathered_info['collected_files']
            total_files = len(files_info)
            total_size = 0
            total_lines = 0
            
            for file_path, file_content in files_info.items():
                # ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã®å–å¾—
                content = self._get_file_content(file_content)
                if content:
                    total_size += len(content)
                    total_lines += len(content.split('\n'))
            
            return f"""**ãƒ•ã‚¡ã‚¤ãƒ«æ•°**: {total_files}å€‹
**ç·æ–‡å­—æ•°**: {total_size:,}æ–‡å­—
**ç·è¡Œæ•°**: {total_lines:,}è¡Œ
**å¹³å‡ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º**: {total_size // total_files if total_files > 0 else 0:,}æ–‡å­—"""
        
        return "ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ"
    
    def _extract_identified_issues(self, state: AgentState, gathered_info: Dict) -> str:
        """ç‰¹å®šã•ã‚ŒãŸå•é¡Œã‚’æŠ½å‡º"""
        if 'collected_files' in gathered_info and gathered_info['collected_files']:
            issues = []
            
            for file_path, file_content in gathered_info['collected_files'].items():
                content = self._get_file_content(file_content)
                if content:
                    # ç°¡å˜ãªå•é¡Œæ¤œå‡º
                    if len(content) > 10000:
                        issues.append(f"- {file_path}: ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãã„ ({len(content):,}æ–‡å­—)")
                    
                    # Markdownãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã®ç°¡å˜ãªãƒã‚§ãƒƒã‚¯
                    if file_path.endswith('.md'):
                        if not content.strip().startswith('#'):
                            issues.append(f"- {file_path}: è¦‹å‡ºã—ã§å§‹ã¾ã£ã¦ã„ãªã„")
                        
                        # é•·ã„è¡Œã®ãƒã‚§ãƒƒã‚¯
                        long_lines = [i+1 for i, line in enumerate(content.split('\n')) if len(line) > 100]
                        if long_lines:
                            issues.append(f"- {file_path}: é•·ã„è¡ŒãŒå­˜åœ¨ (è¡Œç•ªå·: {', '.join(map(str, long_lines[:3]))}{'...' if len(long_lines) > 3 else ''})")
            
            return '\n'.join(issues) if issues else "ç‰¹ç­†ã™ã¹ãå•é¡Œã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ"
        
        return "ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æãŒã§ãã¾ã›ã‚“ã§ã—ãŸ"
    
    def _extract_improvement_suggestions(self, state: AgentState, gathered_info: Dict) -> str:
        """æ”¹å–„ææ¡ˆã‚’æŠ½å‡º"""
        if 'collected_files' in gathered_info and gathered_info['collected_files']:
            suggestions = []
            
            for file_path, file_content in gathered_info['collected_files'].items():
                content = self._get_file_content(file_content)
                if content and file_path.endswith('.md'):
                    # Markdownãƒ•ã‚¡ã‚¤ãƒ«ã®æ”¹å–„ææ¡ˆ
                    if len(content.split('\n')) < 10:
                        suggestions.append(f"- {file_path}: å†…å®¹ã‚’å……å®Ÿã•ã›ã‚‹ã“ã¨ã‚’æ¨å¥¨")
                    
                    if '```' not in content:
                        suggestions.append(f"- {file_path}: ã‚³ãƒ¼ãƒ‰ä¾‹ã®è¿½åŠ ã‚’æ¤œè¨")
                    
                    headers = re.findall(r'^#+\s+(.+)$', content, re.MULTILINE)
                    if len(headers) < 3:
                        suggestions.append(f"- {file_path}: æ§‹é€ åŒ–ã®ãŸã‚è¦‹å‡ºã—ã‚’è¿½åŠ ")
            
            return '\n'.join(suggestions) if suggestions else "ç¾æ™‚ç‚¹ã§ç‰¹åˆ¥ãªæ”¹å–„ææ¡ˆã¯ã‚ã‚Šã¾ã›ã‚“"
        
        return "æ”¹å–„ææ¡ˆã®ç”ŸæˆãŒã§ãã¾ã›ã‚“ã§ã—ãŸ"
    
    def _extract_risk_priority_summary(self, state: AgentState, gathered_info: Dict) -> str:
        """ãƒªã‚¹ã‚¯å„ªå…ˆåº¦è©•ä¾¡ã‚’æŠ½å‡º"""
        if 'collected_files' in gathered_info and gathered_info['collected_files']:
            high_priority = []
            medium_priority = []
            low_priority = []
            
            for file_path, file_content in gathered_info['collected_files'].items():
                content = self._get_file_content(file_content)
                if content:
                    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒ™ãƒ¼ã‚¹ã®å„ªå…ˆåº¦
                    if len(content) > 5000:
                        high_priority.append(f"å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«: {file_path}")
                    elif len(content) > 1000:
                        medium_priority.append(f"ä¸­ã‚µã‚¤ã‚ºãƒ•ã‚¡ã‚¤ãƒ«: {file_path}")
                    else:
                        low_priority.append(f"å°ã•ãªãƒ•ã‚¡ã‚¤ãƒ«: {file_path}")
            
            priority_summary = []
            if high_priority:
                priority_summary.append(f"**é«˜å„ªå…ˆåº¦** ({len(high_priority)}ä»¶): {', '.join(high_priority[:2])}{'...' if len(high_priority) > 2 else ''}")
            if medium_priority:
                priority_summary.append(f"**ä¸­å„ªå…ˆåº¦** ({len(medium_priority)}ä»¶): {', '.join(medium_priority[:2])}{'...' if len(medium_priority) > 2 else ''}")
            if low_priority:
                priority_summary.append(f"**ä½å„ªå…ˆåº¦** ({len(low_priority)}ä»¶): {', '.join(low_priority[:2])}{'...' if len(low_priority) > 2 else ''}")
            
            return '\n'.join(priority_summary) if priority_summary else "å„ªå…ˆåº¦ã®è©•ä¾¡ãŒã§ãã¾ã›ã‚“ã§ã—ãŸ"
        
        return "ãƒªã‚¹ã‚¯è©•ä¾¡ã®ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™"
    
    def _extract_target_name(self, state: AgentState, gathered_info: Dict) -> str:
        return self._extract_target_filename(state, gathered_info)
    
    def _get_file_content(self, file_content) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’çµ±ä¸€çš„ã«å–å¾—ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰"""
        if hasattr(file_content, 'content'):
            return file_content.content
        elif hasattr(file_content, 'file_content'):
            return file_content.file_content
        elif isinstance(file_content, str):
            return file_content
        else:
            return str(file_content)
    
    def _extract_creation_approach(self, state: AgentState, gathered_info: Dict) -> str:
        return "ä½œæˆã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®æ±ºå®šã¯ç¾åœ¨å®Ÿè£…ä¸­ã§ã™"
    
    def _extract_implementation_details(self, state: AgentState, gathered_info: Dict) -> str:
        return "å®Ÿè£…è©³ç´°ã®ç”Ÿæˆã¯ç¾åœ¨å®Ÿè£…ä¸­ã§ã™"
    
    def _extract_risk_considerations(self, state: AgentState, gathered_info: Dict) -> str:
        return "ãƒªã‚¹ã‚¯è€ƒæ…®äº‹é …ã®åˆ†æã¯ç¾åœ¨å®Ÿè£…ä¸­ã§ã™"
    
    def _extract_follow_up_actions(self, state: AgentState, gathered_info: Dict) -> str:
        return "ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ææ¡ˆã¯ç¾åœ¨å®Ÿè£…ä¸­ã§ã™"
    
    def _extract_modification_target(self, state: AgentState, gathered_info: Dict) -> str:
        return self._extract_target_filename(state, gathered_info)
    
    def _extract_affected_files_list(self, state: AgentState, gathered_info: Dict) -> str:
        return "å½±éŸ¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ç‰¹å®šã¯ç¾åœ¨å®Ÿè£…ä¸­ã§ã™"
    
    def _extract_modification_details(self, state: AgentState, gathered_info: Dict) -> str:
        return "å¤‰æ›´è©³ç´°ã®åˆ†æã¯ç¾åœ¨å®Ÿè£…ä¸­ã§ã™"
    
    def _extract_change_impact_summary(self, state: AgentState, gathered_info: Dict) -> str:
        return "å¤‰æ›´å½±éŸ¿ã®åˆ†æã¯ç¾åœ¨å®Ÿè£…ä¸­ã§ã™"
    
    def _extract_backup_and_safety_info(self, state: AgentState, gathered_info: Dict) -> str:
        return "ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¨å®‰å…¨å¯¾ç­–ã®æƒ…å ±ã¯ç¾åœ¨å®Ÿè£…ä¸­ã§ã™"
    
    def _extract_search_term(self, state: AgentState, gathered_info: Dict) -> str:
        return "æ¤œç´¢ã‚¯ã‚¨ãƒªã®æŠ½å‡ºã¯ç¾åœ¨å®Ÿè£…ä¸­ã§ã™"
    
    def _extract_discovered_files_list(self, state: AgentState, gathered_info: Dict) -> str:
        return "ç™ºè¦‹ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¹ãƒˆç”Ÿæˆã¯ç¾åœ¨å®Ÿè£…ä¸­ã§ã™"
    
    def _extract_code_snippets(self, state: AgentState, gathered_info: Dict) -> str:
        return "ã‚³ãƒ¼ãƒ‰ã‚¹ãƒ‹ãƒšãƒƒãƒˆã®æŠ½å‡ºã¯ç¾åœ¨å®Ÿè£…ä¸­ã§ã™"
    
    def _extract_search_statistics(self, state: AgentState, gathered_info: Dict) -> str:
        return "æ¤œç´¢çµ±è¨ˆã®ç”Ÿæˆã¯ç¾åœ¨å®Ÿè£…ä¸­ã§ã™"
    
    def _extract_additional_findings(self, state: AgentState, gathered_info: Dict) -> str:
        return "è¿½åŠ ç™ºè¦‹äº‹é …ã¯ç¾åœ¨å®Ÿè£…ä¸­ã§ã™"
    
    def _extract_guidance_topic(self, state: AgentState, gathered_info: Dict) -> str:
        return "ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ãƒˆãƒ”ãƒƒã‚¯ã®æŠ½å‡ºã¯ç¾åœ¨å®Ÿè£…ä¸­ã§ã™"
    
    def _extract_requirement_list(self, state: AgentState, gathered_info: Dict) -> str:
        return "å‰ææ¡ä»¶ã®æŠ½å‡ºã¯ç¾åœ¨å®Ÿè£…ä¸­ã§ã™"
    
    def _extract_step_by_step_guide(self, state: AgentState, gathered_info: Dict) -> str:
        return "ã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—ã‚¬ã‚¤ãƒ‰ã®ç”Ÿæˆã¯ç¾åœ¨å®Ÿè£…ä¸­ã§ã™"
    
    def _extract_troubleshooting_info(self, state: AgentState, gathered_info: Dict) -> str:
        return "ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°æƒ…å ±ã¯ç¾åœ¨å®Ÿè£…ä¸­ã§ã™"
    
    def _extract_best_practices(self, state: AgentState, gathered_info: Dict) -> str:
        return "ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã®ææ¡ˆã¯ç¾åœ¨å®Ÿè£…ä¸­ã§ã™"
    
    def _fill_template(self, template, data: Dict[str, str]) -> str:
        """ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«ãƒ‡ãƒ¼ã‚¿ã‚’åŸ‹ã‚è¾¼ã¿
        
        Args:
            template: TaskProfileTemplate
            data: åŸ‹ã‚è¾¼ã‚€ãƒ‡ãƒ¼ã‚¿ã®è¾æ›¸
            
        Returns:
            ãƒ‡ãƒ¼ã‚¿ãŒåŸ‹ã‚è¾¼ã¾ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
        """
        result = template.structure
        
        for placeholder, value in data.items():
            pattern = "{" + placeholder + "}"
            result = result.replace(pattern, str(value))
        
        return result
    
    def _format_markdown(self, content: str) -> str:
        """Markdownã®æ•´å½¢
        
        Args:
            content: æ•´å½¢å‰ã®Markdown
            
        Returns:
            æ•´å½¢å¾Œã®Markdown
        """
        # ç©ºè¡Œã®çµ±ä¸€
        content = re.sub(r'\n{3,}', '\n\n', content)
        
        # å…ˆé ­ã¨æœ«å°¾ã®ç©ºç™½ã‚’é™¤å»
        content = content.strip()
        
        # ç”Ÿæˆæ—¥æ™‚ã‚’è¿½åŠ 
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        footer = f"\n\n---\n*Generated by Duckflow at {timestamp}*"
        
        return content + footer
    
    def _integrate_pecking_order_info(self, state: AgentState, extracted_data: Dict[str, str]) -> None:
        """The Pecking Orderæƒ…å ±ã‚’å¿œç­”ãƒ‡ãƒ¼ã‚¿ã«çµ±åˆã™ã‚‹
        
        Args:
            state: AgentState
            extracted_data: æŠ½å‡ºæ¸ˆã¿ãƒ‡ãƒ¼ã‚¿è¾æ›¸ï¼ˆå¤‰æ›´ã•ã‚Œã‚‹ï¼‰
        """
        try:
            # The Pecking Orderæƒ…å ±ã‚’å–å¾—
            pecking_order_status = state.get_pecking_order_status()
            current_task = state.get_current_task()
            
            if pecking_order_status:
                # é€²æ—æƒ…å ±ã‚’çµ±åˆ
                completion_rate = pecking_order_status.get('completion_rate', 0.0)
                total_tasks = pecking_order_status.get('total_tasks', 0)
                remaining_tasks = pecking_order_status.get('pending_tasks', 0)
                
                # æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ã«é€²æ—æƒ…å ±ã‚’è¿½åŠ 
                extracted_data['current_task_progress'] = f"{completion_rate:.1%}"
                extracted_data['remaining_tasks_count'] = str(remaining_tasks)
                extracted_data['total_tasks_count'] = str(total_tasks)
                
                # ã‚¿ã‚¹ã‚¯éšå±¤æƒ…å ±ã‚’è¿½åŠ 
                if state.task_tree:
                    hierarchy_str = state.get_pecking_order_string()
                    extracted_data['task_hierarchy'] = hierarchy_str
                
                # ç¾åœ¨ã®ã‚¿ã‚¹ã‚¯æƒ…å ±ã‚’è¿½åŠ 
                if current_task:
                    extracted_data['current_task_description'] = current_task.description
                    extracted_data['current_task_status'] = current_task.status.value
                
                rich_ui.print_message(f"[RESPONSE] The Pecking Orderæƒ…å ±ã‚’çµ±åˆ: {completion_rate:.1%}å®Œäº†", "info")
            
        except Exception as e:
            rich_ui.print_warning(f"The Pecking Orderæƒ…å ±çµ±åˆã‚¨ãƒ©ãƒ¼: {e}")
            # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å€¤ã‚’è¨­å®š
            extracted_data['current_task_progress'] = "0.0%"
            extracted_data['remaining_tasks_count'] = "0"
            extracted_data['total_tasks_count'] = "0"
            extracted_data['task_hierarchy'] = "ã‚¿ã‚¹ã‚¯éšå±¤æƒ…å ±ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“"
    
    def _generate_error_response(self, error_message: str) -> str:
        """ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¿œç­”ã‚’ç”Ÿæˆ
        
        Args:
            error_message: ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            
        Returns:
            ã‚¨ãƒ©ãƒ¼å¿œç­”ã®Markdown
        """
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        return f"""## âŒ å‡¦ç†ã‚¨ãƒ©ãƒ¼

ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚

### ã‚¨ãƒ©ãƒ¼è©³ç´°
{error_message}

### å¯¾å‡¦æ–¹æ³•
1. è¦æ±‚ã‚’å†åº¦ç¢ºèªã—ã¦ãã ã•ã„
2. å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„  
3. ã‚¨ãƒ©ãƒ¼ãŒç¶™ç¶šã™ã‚‹å ´åˆã¯ã€ã‚ˆã‚Šå…·ä½“çš„ãªæŒ‡ç¤ºã‚’ãŠè©¦ã—ãã ã•ã„

---
*Generated by Duckflow at {timestamp}*"""


# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
response_generation_node = ResponseGenerationNode()