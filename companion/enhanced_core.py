"""
EnhancedCompanionCore - Step 2: æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ çµ±åˆç‰ˆ
AgentStateã€ConversationMemoryã€PromptCompilerã¨ã®çµ±åˆ
"""

import asyncio
import uuid
from typing import Optional, Dict, Any, List
from datetime import datetime

# æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã¨ã®çµ±åˆ
from companion.state.agent_state import AgentState
from .memory.conversation_memory import conversation_memory
from .prompts.prompt_compiler import prompt_compiler
from .prompts.context_builder import PromptContextBuilder
from .base.llm_client import llm_manager
from .ui import rich_ui
from companion.validators.llm_output import LLMOutputFormatter, MainLLMOutput
from companion.state.agent_state import Step
from companion.prompts.context_assembler import ContextAssembler

# æ—¢å­˜ã®CompanionCoreæ©Ÿèƒ½
from .core import CompanionCore, ActionType
from .simple_approval import ApprovalMode
from .shared_context_manager import SharedContextManager
from .plan_tool import PlanTool, MessageRef


class EnhancedCompanionCore:
    """æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ çµ±åˆç‰ˆCompanionCore
    
    Step 2ã®æ”¹å–„:
    - AgentStateã«ã‚ˆã‚‹çµ±ä¸€çŠ¶æ…‹ç®¡ç†ï¼ˆå˜ä¸€ã‚½ãƒ¼ã‚¹ãƒ»ã‚ªãƒ–ãƒ»ãƒˆã‚¥ãƒ«ãƒ¼ã‚¹ï¼‰
    - ConversationMemoryã«ã‚ˆã‚‹è‡ªå‹•è¨˜æ†¶è¦ç´„
    - PromptCompilerã«ã‚ˆã‚‹é«˜åº¦ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€é©åŒ–
    - PromptContextBuilderã«ã‚ˆã‚‹æ§‹é€ åŒ–ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç®¡ç†
    
    çŠ¶æ…‹ç®¡ç†çµ±ä¸€ï¼ˆæ”¹ä¿®å¾Œï¼‰:
    - AgentState: å”¯ä¸€ã®æ›¸ãè¾¼ã¿å¯èƒ½ãªçŠ¶æ…‹ã‚½ãƒ¼ã‚¹
    - Legacy CompanionCore: èª­ã¿å–ã‚Šå°‚ç”¨ãƒŸãƒ©ãƒ¼ï¼ˆAgentState â†’ Legacy ã®ä¸€æ–¹å‘åŒæœŸï¼‰
    - çŠ¶æ…‹ã®ç«¶åˆã¨äºŒé‡åŒ–å•é¡Œã‚’è§£æ±º
    """
    
    def __init__(self, session_id: Optional[str] = None, approval_mode: ApprovalMode = ApprovalMode.STANDARD):
        """åˆæœŸåŒ–
        
        Args:
            session_id: ã‚»ãƒƒã‚·ãƒ§ãƒ³IDï¼ˆçœç•¥æ™‚ã¯è‡ªå‹•ç”Ÿæˆï¼‰
            approval_mode: æ‰¿èªãƒ¢ãƒ¼ãƒ‰
        """
        # AgentStateã‚’åˆæœŸåŒ–
        self.state = AgentState(
            session_id=session_id or str(uuid.uuid4())
        )
        
        # æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã¨ã®çµ±åˆ
        
        # ãƒ—ãƒ©ãƒ³çŠ¶æ…‹ç®¡ç†ï¼ˆå®Ÿè¡Œé˜»å®³æ”¹å–„ï¼‰
        self.current_plan_state = {
            "pending": False,
            "plan_content": None,
            "plan_type": None,
            "created_at": None
        }
        self.memory_manager = conversation_memory
        self.prompt_compiler = prompt_compiler
        self.context_builder = PromptContextBuilder()
        
        # æ—¢å­˜ã®CompanionCoreã‚‚ä¿æŒï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰
        self.legacy_companion = CompanionCore(approval_mode=approval_mode)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œçµ±åˆ
        from .file_ops import SimpleFileOps
        self.file_ops = SimpleFileOps(approval_mode=approval_mode)
        
        # PlanToolçµ±åˆ
        self.plan_tool = PlanTool()
        
        # Phase 1.6: ã‚³ãƒ¼ãƒ‰å®Ÿè¡Œæ©Ÿèƒ½çµ±åˆ
        from .code_runner import SimpleCodeRunner
        self.code_runner = SimpleCodeRunner(approval_mode=approval_mode)
        
        # çµ±åˆãƒ¢ãƒ¼ãƒ‰ãƒ•ãƒ©ã‚°
        self.use_enhanced_mode = True
        # LLMå‡ºåŠ›ãƒãƒªãƒ‡ãƒ¼ã‚¿ï¼ˆPhase 1ï¼‰
        self.llm_output_formatter = LLMOutputFormatter()
        # Phase 2: Context Assemblerï¼ˆBase+Mainï¼‰
        self.context_assembler = ContextAssembler()
        
        # ãƒ­ã‚°è¨­å®š
        import logging
        self.logger = logging.getLogger(__name__)
    
    def _generate_plan_unified(self, user_input: str):
        """çµ±ä¸€ãƒ—ãƒ©ãƒ³ç”Ÿæˆï¼ˆå…¨ãƒ‘ã‚¹ã§ä½¿ç”¨ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå¼•ãç¶™ãå¯¾å¿œï¼‰"""
        try:
            # çŸ­æœŸè¨˜æ†¶ã‹ã‚‰ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
            short_term_memory = getattr(self.state, 'short_term_memory', {})
            last_read_file = short_term_memory.get('last_read_file')

            # ãƒ—ãƒ©ãƒ³ç”Ÿæˆã®ãŸã‚ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å‹•çš„ã«æ§‹ç¯‰
            if last_read_file:
                plan_generation_prompt = f"""
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦æ±‚: {user_input}

é–¢é€£ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ:
ç›´å‰ã«ãƒ•ã‚¡ã‚¤ãƒ«ã€Œ{last_read_file.get('path')}ã€ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚
ãã®ãƒ•ã‚¡ã‚¤ãƒ«ã®è¦ç´„ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚
---
{last_read_file.get('summary', 'ãªã—')}
---

ä¸Šè¨˜ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å®Œå…¨ã«è¸ã¾ãˆãŸä¸Šã§ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦æ±‚ã«å¯¾ã™ã‚‹å…·ä½“çš„ãªå®Ÿè£…ãƒ—ãƒ©ãƒ³ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
"""
                rationale = f"ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æ±‚ï¼ˆ{user_input[:50]}...ï¼‰ã¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆ{last_read_file.get('path')}ï¼‰ã«åŸºã¥ã"
            else:
                plan_generation_prompt = user_input
                rationale = f"ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æ±‚: {user_input[:100]}..."

            # ãƒ—ãƒ©ãƒ³ä½œæˆã«å¿…è¦ãªå¼•æ•°ã‚’æº–å‚™
            from .plan_tool import MessageRef
            sources = [MessageRef(message_id="user_request", timestamp=datetime.now().isoformat())]
            tags = ["user_request", "auto_generated", "context_aware"]

            # ãƒ—ãƒ©ãƒ³ä½œæˆ
            plan_id = self.plan_tool.propose(plan_generation_prompt, sources, rationale, tags)

            # ActionSpecä¿è¨¼ï¼ˆActionSpecã®ç”Ÿæˆã¯å…ƒã®å…¥åŠ›ã§è¡Œã†ï¼‰
            self._ensure_action_specs(plan_id, user_input)

            # æ‰¿èªè¦æ±‚
            from .plan_tool import SpecSelection
            self.plan_tool.request_approval(plan_id, SpecSelection(all=True))

            return plan_id

        except Exception as e:
            self.logger.error(f"çµ±ä¸€ãƒ—ãƒ©ãƒ³ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            raise
    
    def _ensure_action_specs(self, plan_id: str, content: str):
        """ActionSpecä¿è¨¼ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãªã—ï¼‰"""
        from .collaborative_planner import ActionSpec
        
        # å‹•çš„ãªãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã¨èª¬æ˜ã®ç”Ÿæˆ
        file_path = self._generate_dynamic_file_path(content)
        description = self._generate_dynamic_description(content)
        
        action_spec = ActionSpec(
            kind='implement',
            path=file_path,
            description=description,
            optional=False
        )
        
        # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ä¾‹å¤–ã‚’æŠ•ã’ã‚‹ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãªã—ï¼‰
        self.plan_tool.set_action_specs(plan_id, [action_spec])
    
    def _generate_dynamic_file_path(self, content: str) -> str:
        """å‹•çš„ãªãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’ç”Ÿæˆ"""
        if "è¨ˆç”»" in content or "ãƒ—ãƒ©ãƒ³" in content:
            return "plan.md"
        elif "å®Ÿè£…" in content:
            return "implementation.md"
        elif "ä½œæˆ" in content:
            return "implementation.md"
        elif "è¨­è¨ˆ" in content or "ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£" in content:
            return "design.md"
        else:
            return "task.md"
    
    def _generate_dynamic_description(self, content: str) -> str:
        """å‹•çš„ãªèª¬æ˜ã‚’ç”Ÿæˆ"""
        if "å®Ÿè£…" in content:
            return f"ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æ±‚ã«åŸºã¥ãå®Ÿè£…: {content[:100]}..."
        elif "è¨ˆç”»" in content:
            return f"ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æ±‚ã«åŸºã¥ãè¨ˆç”»ä½œæˆ: {content[:100]}..."
        elif "è¨­è¨ˆ" in content:
            return f"ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æ±‚ã«åŸºã¥ãè¨­è¨ˆ: {content[:100]}..."
        else:
            return f"ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æ±‚ã®å‡¦ç†: {content[:100]}..."
    
    async def analyze_intent_only(self, user_message: str, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """çµ±åˆç‰ˆæ„å›³ç†è§£ï¼ˆAgentStateæ´»ç”¨ï¼‰"""
        try:
            if self.use_enhanced_mode:
                return await self._analyze_intent_enhanced(user_message, context)
            else:
                return await self.legacy_companion.analyze_intent_only(user_message)
        except Exception as e:
            self.logger.error(f"çµ±åˆç‰ˆæ„å›³ç†è§£ã‚¨ãƒ©ãƒ¼: {e}")
            return await self.legacy_companion.analyze_intent_only(user_message)
    
    async def _analyze_intent_enhanced(self, user_message: str, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """æ‹¡å¼µç‰ˆæ„å›³ç†è§£ï¼ˆæ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ æ´»ç”¨ï¼‰"""
        self.state.add_message("user", user_message)
        if self.state.needs_memory_management():
            if self.state.create_memory_summary():
                rich_ui.print_message("ğŸ§  ä¼šè©±å±¥æ­´ã‚’è¦ç´„ã—ã¾ã—ãŸ", "info")
        self._sync_to_legacy_readonly()
        
        result = await self.legacy_companion.analyze_intent_only(user_message)
        understanding_result = result.get("understanding_result")

        result_payload = {
            "action_type": result["action_type"],
            "understanding_result": understanding_result,
            "message": user_message,
            "enhanced_mode": True,
            "session_id": self.state.session_id,
            "conversation_count": len(self.state.conversation_history)
        }

        if understanding_result:
            try:
                result_payload.update({
                    "route_type": getattr(understanding_result, 'route_type', None),
                    "risk_level": getattr(understanding_result, 'risk_level', None),
                    "prerequisite_status": getattr(understanding_result, 'prerequisite_status', None),
                    "routing_reason": getattr(understanding_result, 'routing_reason', None),
                    "metadata": getattr(understanding_result, 'metadata', None)
                })
            except Exception:
                pass

        try:
            main_json = self._build_main_llm_output(result_payload)
            validated = self.llm_output_formatter.validate(main_json)
            result_payload["main_llm_output"] = validated.model_dump()
        except Exception:
            repaired = self.llm_output_formatter.try_repair(main_json if 'main_json' in locals() else {})
            if repaired:
                result_payload["main_llm_output"] = repaired.model_dump()
            else:
                result_payload["main_llm_output_error"] = "validation_failed"

        return result_payload

    def _build_main_llm_output(self, intent_result: Dict[str, Any]) -> Dict[str, Any]:
        """æ„å›³ç†è§£çµæœã‹ã‚‰æœ€å°ã®Main LLM JSONã‚’åˆæˆ"""
        action_type = intent_result.get("action_type")
        action_val = getattr(action_type, 'value', str(action_type))
        next_step = "continue" if action_val in ["direct_response", "file_operation"] else "defer"
        
        return {
            "rationale": "æ„å›³åˆ†æã«åŸºã¥ãæ¬¡ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®æ±ºå®š",
            "goal_consistency": "yes: ç›®æ¨™ã¨æ•´åˆ" if getattr(self.state, 'goal', '') else "yes: ç›®æ¨™æœªè¨­å®š",
            "constraint_check": "yes: åˆ¶ç´„ã‚’å°Šé‡" if getattr(self.state, 'constraints', []) else "yes: åˆ¶ç´„ãªã—",
            "next_step": next_step,
            "step": self.state.step.value if isinstance(self.state.step, Step) else str(self.state.step),
            "state_delta": getattr(self.state, 'last_delta', "")
        }
    
    async def process_with_intent_result(self, intent_result: Dict[str, Any]) -> str:
        """æ„å›³ç†è§£çµæœã‚’å†åˆ©ç”¨ã—ã¦ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡¦ç† (ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ç‰ˆ)"""
        if not (self.use_enhanced_mode and intent_result.get("enhanced_mode")):
            return await self.legacy_companion.process_with_intent_result(intent_result)

        try:
            user_message = intent_result["message"]
            action_type = intent_result["action_type"]
            understanding_result = intent_result.get("understanding_result")

            self.legacy_companion._show_thinking_process(user_message)

            # --- 3å±¤ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ§‹ç¯‰ ---
            main_context_id = self.context_builder.from_agent_state(self.state)
            main_context_prompt = self.context_builder.build_prompt(main_context_id, "text")

            specialized_prompt = ""
            prompt_pattern = getattr(understanding_result, 'prompt_pattern', 'base_main')
            self.logger.info(f"LLMã«ã‚ˆã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³é¸æŠ: {prompt_pattern}")

            if prompt_pattern == 'base_main_specialized':
                try:
                    from .prompts.specialized_prompt_generator import SpecializedPromptGenerator
                    specialized_generator = SpecializedPromptGenerator()
                    current_step = self.state.step
                    if current_step in [Step.PLANNING, Step.EXECUTION, Step.REVIEW]:
                        specialized_prompt = specialized_generator.generate(current_step.value, self.state.model_dump())
                except Exception as e:
                    self.logger.error(f"Specializedãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")

            system_prompt = f"{main_context_prompt}\n\n{specialized_prompt}".strip()
            
            # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
            if action_type == ActionType.DIRECT_RESPONSE:
                result = await self._generate_enhanced_response(user_message, system_prompt)
            elif action_type == ActionType.FILE_OPERATION:
                result = await self._handle_enhanced_file_operation(user_message, system_prompt)
            elif action_type == ActionType.CODE_EXECUTION:
                result = self.legacy_companion._handle_code_execution(user_message)
            else:
                result = self.legacy_companion._handle_multi_step_task(user_message)
            
            if self._looks_like_plan(result):
                self.set_plan_state(result, "execution_plan")
            
            self.state.add_message("assistant", result)
            self._sync_to_legacy_readonly()
            
            return result
        except Exception as e:
            self.logger.error(f"çµ±åˆç‰ˆå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return await self.legacy_companion.process_with_intent_result(intent_result)
    
    def _build_recent_conversation_context(self) -> str:
        """ç›´è¿‘ã®ä¼šè©±å±¥æ­´ã‹ã‚‰é‡è¦ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰"""
        try:
            if not self.state.conversation_history:
                return ""
            
            recent_messages = self.state.conversation_history[-3:]
            context_parts = []
            
            for msg in recent_messages:
                role = msg.get("role", "unknown")
                content = msg.get("content", "")[:150]
                if content:
                    context_parts.append(f"{role}: {content}")
            
            return "ç›´è¿‘ã®ä¼šè©±:\n" + "\n".join(context_parts) if context_parts else ""
            
        except Exception as e:
            self.logger.warning(f"ä¼šè©±ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ§‹ç¯‰ã‚¨ãƒ©ãƒ¼: {e}")
            return ""
    
    def _build_session_summary(self) -> str:
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³å…¨ä½“ã®è¦ç´„ã‚’æ§‹ç¯‰"""
        try:
            summary_parts = []
            if hasattr(self.state, 'created_at'):
                summary_parts.append(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹: {self.state.created_at.strftime('%H:%M:%S')}")
            if self.state.conversation_history:
                summary_parts.append(f"ä¼šè©±æ•°: {len(self.state.conversation_history)}ä»¶")
            if hasattr(self.state, 'step'):
                summary_parts.append(f"ç¾åœ¨ã®ã‚¹ãƒ†ãƒƒãƒ—: {getattr(self.state.step, 'value', str(self.state.step))}")
            
            return "ã‚»ãƒƒã‚·ãƒ§ãƒ³æ¦‚è¦:\n" + "\n".join(summary_parts) if summary_parts else ""
            
        except Exception as e:
            self.logger.warning(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³è¦ç´„æ§‹ç¯‰ã‚¨ãƒ©ãƒ¼: {e}")
            return ""
    
    def _record_file_operation(self, operation_type: str, file_path: str, content_summary: str = ""):
        """ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œå±¥æ­´ã‚’è¨˜éŒ²"""
        try:
            if 'file_operations' not in self.state.short_term_memory:
                self.state.short_term_memory['file_operations'] = []
            
            operation_record = {
                'type': operation_type,
                'path': file_path,
                'timestamp': datetime.now().isoformat(),
                'summary': content_summary
            }
            
            self.state.short_term_memory['file_operations'].append(operation_record)
            
            if len(self.state.short_term_memory['file_operations']) > 10:
                self.state.short_term_memory['file_operations'] = self.state.short_term_memory['file_operations'][-10:]
                
        except Exception as e:
            self.logger.warning(f"ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œå±¥æ­´è¨˜éŒ²ã‚¨ãƒ©ãƒ¼: {e}")
    
    async def _collect_file_context(self) -> Dict[str, Any]:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’åé›†ï¼ˆç›´è¿‘ã®æ“ä½œå±¥æ­´ã‚’å«ã‚€ï¼‰"""
        try:
            file_operations = []
            if file_ops := getattr(self.state, 'short_term_memory', {}).get('file_operations', []):
                for op in file_ops[-5:]:
                    if isinstance(op, dict):
                        file_operations.append(f"{op.get('type', '?')}: {op.get('path', '?')}")
            
            return {"file_operations_history": file_operations}
            
        except Exception as e:
            self.logger.warning(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåé›†ã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    
    def set_plan_state(self, plan_content: str, plan_type: str = "execution_plan"):
        """ãƒ—ãƒ©ãƒ³çŠ¶æ…‹ã‚’è¨­å®šï¼ˆPlanToolçµ±åˆç‰ˆï¼‰"""
        try:
            plan_id = self.plan_tool.propose(
                content=plan_content,
                sources=[MessageRef(message_id=str(uuid.uuid4()), timestamp=datetime.now().isoformat())],
                rationale=f"AIç”Ÿæˆãƒ—ãƒ©ãƒ³: {plan_type}",
                tags=[plan_type, "ai_generated"]
            )
            self.current_plan_state = {
                "pending": True,
                "plan_content": plan_content,
                "plan_type": plan_type,
                "created_at": datetime.now(),
                "plan_id": plan_id
            }
        except Exception as e:
            self.logger.error(f"PlanToolçµ±åˆã‚¨ãƒ©ãƒ¼: {e}")
            self.current_plan_state = {"pending": True, "plan_content": plan_content, "plan_type": plan_type, "created_at": datetime.now()}
        
        self.state.short_term_memory["current_plan_state"] = self.current_plan_state
        self._record_file_operation("plan_creation", f"plan_{plan_type}", plan_content[:100])
    
    def get_plan_state(self) -> Dict[str, Any]:
        """ç¾åœ¨ã®ãƒ—ãƒ©ãƒ³çŠ¶æ…‹ã‚’å–å¾—"""
        return self.current_plan_state
    
    def clear_plan_state(self):
        """ãƒ—ãƒ©ãƒ³çŠ¶æ…‹ã‚’ã‚¯ãƒªã‚¢"""
        self.plan_tool.clear_current()
        self.current_plan_state = {"pending": False, "plan_content": None, "plan_type": None, "created_at": None}
        if "current_plan_state" in self.state.short_term_memory:
            del self.state.short_term_memory["current_plan_state"]

    def _looks_like_plan(self, text: str) -> bool:
        """å¿œç­”ãƒ†ã‚­ã‚¹ãƒˆãŒã€Œå®Ÿè£…ãƒ—ãƒ©ãƒ³/ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—ã€çš„ã‹ã‚’ç°¡æ˜“åˆ¤å®š"""
        if not text or len(text) < 50: return False
        import re
        indicators = ["å®Ÿè£…ãƒ—ãƒ©ãƒ³", "ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—", "ãƒ•ã‚§ãƒ¼ã‚º", "æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—", "ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ ", "ã‚¿ã‚¹ã‚¯å®Ÿè¡Œè¨ˆç”»"]
        return sum(1 for kw in indicators if kw in text) >= 2 and bool(re.search(r"\n\s*\d+\|\|\n\s*-\s", text))

    def _summarize_plan_for_context(self, text: str) -> str:
        """PlanContext ç”¨ã®è»½ã„è¦ç´„"""
        lines = text.splitlines()
        header = next((l for l in lines if l.strip().startswith("#")), "")
        bullets = [l.strip() for l in lines if l.strip().startswith(("- ", "1."))][:5]
        return "\n".join([header] + bullets)
    
    async def _generate_enhanced_response(self, user_message: str, system_prompt: str) -> str:
        """æ‹¡å¼µç‰ˆç›´æ¥å¿œç­”ç”Ÿæˆ"""
        try:
            rich_ui.print_message("ğŸ’¬ æ‹¡å¼µã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§å¿œç­”ã‚’ç”Ÿæˆä¸­...", "info")
            messages = [{"role": "system", "content": system_prompt}]
            if self.state.conversation_history:
                for msg in self.state.conversation_history[-10:]:
                    if msg.role in ["user", "assistant"]:
                        messages.append({"role": msg.role, "content": msg.content})
            messages.append({"role": "user", "content": user_message})
            response = await llm_manager.generate(prompt=user_message, metadata={'system_prompt': system_prompt})
            rich_ui.print_message("âœ¨ æ‹¡å¼µå¿œç­”ã‚’ç”Ÿæˆã—ã¾ã—ãŸï¼", "success")
            return response
        except Exception as e:
            self.logger.error(f"æ‹¡å¼µå¿œç­”ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return self.legacy_companion._generate_direct_response(user_message)
    
    async def _handle_enhanced_file_operation(self, user_message: str, system_prompt: str) -> str:
        """æ‹¡å¼µç‰ˆãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œå‡¦ç†"""
        try:
            rich_ui.print_message("ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œã‚¿ã‚¹ã‚¯ã¨ã—ã¦å‡¦ç†ä¸­...", "info")
            file_path = await self._extract_file_path_from_llm(user_message)

            if any(kw in user_message for kw in ["èª­", "ç¢ºèª", "å†…å®¹", "è¦‹ã¦"]):
                return await self._handle_file_read_operation(user_message)
            elif any(kw in user_message for kw in ["ãƒ—ãƒ©ãƒ³", "è¨ˆç”»"]) and not file_path:
                plan = self._generate_plan_unified(user_message)
                return plan
            elif any(kw in user_message for kw in ["æ›¸", "ä½œæˆ"]) and file_path:
                return await self._handle_file_write_operation(user_message)
            elif any(kw in user_message for kw in ["ä¸€è¦§", "ls"]):
                return await self._handle_file_list_operation(user_message)
            else:
                return await self._generate_enhanced_response(user_message, system_prompt)
        except Exception as e:
            self.logger.error(f"æ‹¡å¼µãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œã‚¨ãƒ©ãƒ¼: {e}")
            return self.legacy_companion._handle_file_operation(user_message)
    
    async def _handle_file_read_operation(self, user_message: str) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿æ“ä½œã‚’å‡¦ç†"""
        try:
            # LLMã®å‡ºåŠ›ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å–å¾—
            file_path = await self._extract_file_path_from_llm(user_message)
            
            rich_ui.print_message(f"ğŸ“– ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿: {file_path}", "info")
            content = self.file_ops.read_file(file_path)
            summary = await self._generate_file_summary(file_path, content)

            self.state.short_term_memory["last_read_file"] = {
                "path": file_path,
                "summary": summary,
                "length": len(content),
                "timestamp": datetime.now().isoformat()
            }
            self._record_file_operation("read", file_path, summary)
            self.state.add_message("assistant", f"ãƒ•ã‚¡ã‚¤ãƒ« '{file_path}' ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
            return f"ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ« '{file_path}' ã®å†…å®¹:\n\n{summary}\n\n--- å®Œå…¨ãªå†…å®¹ ---\n{content}"
        except Exception as e:
            return f"ãƒ•ã‚¡ã‚¤ãƒ« '{file_path}' ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}"
    
    async def _extract_file_path_from_llm(self, user_message: str) -> str:
        """LLMã®å‡ºåŠ›ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’æŠ½å‡º"""
        try:
            # LLMã«ãƒ•ã‚¡ã‚¤ãƒ«åæŠ½å‡ºã‚’ä¾é ¼
            extraction_prompt = f"""ä»¥ä¸‹ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰ã€æ“ä½œå¯¾è±¡ã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æ­£ç¢ºã«æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {user_message}

ä»¥ä¸‹ã®JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„:
{{
    "file_target": "ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆä¾‹: game_doc.mdï¼‰",
    "action": "å®Ÿè¡Œã™ã‚‹ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆä¾‹: read_fileï¼‰",
    "reasoning": "ãªãœã“ã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æŠ½å‡ºã—ãŸã‹ã®ç†ç”±"
}}

ãƒ•ã‚¡ã‚¤ãƒ«åã®ã¿ã‚’æŠ½å‡ºã—ã€ä½™åˆ†ãªæ–‡å­—ã¯å«ã‚ãªã„ã§ãã ã•ã„ã€‚"""

            response = await llm_manager.generate(extraction_prompt)
            
            # JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ‘ãƒ¼ã‚¹
            import json
            try:
                # JSONéƒ¨åˆ†ã‚’æŠ½å‡º
                json_start = response.find('{')
                json_end = response.rfind('}') + 1
                if json_start >= 0 and json_end > json_start:
                    json_str = response[json_start:json_end]
                    parsed = json.loads(json_str)
                    file_target = parsed.get('file_target', '')
                    
                    if file_target:
                        return file_target
            except Exception as e:
                self.logger.warning(f"JSONãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
            
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: åŸºæœ¬çš„ãªãƒ•ã‚¡ã‚¤ãƒ«åæŠ½å‡º
            return self._fallback_file_extraction(user_message)
            
        except Exception as e:
            self.logger.error(f"LLMãƒ•ã‚¡ã‚¤ãƒ«åæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return self._fallback_file_extraction(user_message)
    
    def _fallback_file_extraction(self, user_message: str) -> str:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®ãƒ•ã‚¡ã‚¤ãƒ«åæŠ½å‡º"""
        import re
        
        # .md, .txt, .py ãªã©ã®æ‹¡å¼µå­ã‚’æŒã¤ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æ¢ã™
        file_extensions = r'\.(md|txt|py|js|html|css|json|yaml|yml|xml|csv|log)$'
        file_match = re.search(r'(\S+' + file_extensions + r')', user_message)
        if file_match:
            return file_match.group(1)
        
        # ä¸€èˆ¬çš„ãªãƒ•ã‚¡ã‚¤ãƒ«åãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¢ã™
        words = user_message.split()
        for word in words:
            if re.search(r'\.\w+$', word):
                return word
        
        # æœ€å¾Œã®æ‰‹æ®µï¼šæœ€åˆã®å˜èª
        return words[0] if words else "unknown_file"
    
    async def _handle_file_write_operation(self, user_message: str) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãè¾¼ã¿æ“ä½œã‚’å‡¦ç†"""
        # ... (Implementation omitted for brevity)
        return "ãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãè¾¼ã¿ã¯ç¾åœ¨å®Ÿè£…ä¸­ã§ã™ã€‚"
    
    async def _handle_file_list_operation(self, user_message: str) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§æ“ä½œã‚’å‡¦ç†"""
        # ... (Implementation omitted for brevity)
        return "ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã¯ç¾åœ¨å®Ÿè£…ä¸­ã§ã™ã€‚"

    async def _generate_file_summary(self, file_path: str, content: str) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã®è¦ç´„ã‚’ç”Ÿæˆ"""
        if len(content) < 200: return "(å†…å®¹ãŒçŸ­ã„ãŸã‚è¦ç´„çœç•¥)"
        try:
            summary_prompt = f"ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’3-5è¡Œã§ç°¡æ½”ã«è¦ç´„ã—ã¦ãã ã•ã„ã€‚\n\nãƒ•ã‚¡ã‚¤ãƒ«: {file_path}\n\nå†…å®¹:{content[:3000]}"
            summary = await llm_manager.generate(summary_prompt)
            return f"ğŸ“‹ è¦ç´„:\n{summary}"
        except Exception as e:
            self.logger.warning(f"ãƒ•ã‚¡ã‚¤ãƒ«è¦ç´„ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return "(è¦ç´„ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ)"
    
    def get_agent_state(self) -> AgentState:
        return self.state
    
    def get_session_summary(self) -> Dict[str, Any]:
        return {
            **self.state.get_context_summary(),
            "memory_status": self.state.get_memory_status(),
            "enhanced_mode": self.use_enhanced_mode
        }

    def toggle_enhanced_mode(self, enabled: bool = None) -> bool:
        if enabled is None:
            self.use_enhanced_mode = not self.use_enhanced_mode
        else:
            self.use_enhanced_mode = enabled
        rich_ui.print_message(f"ğŸ”§ æ‹¡å¼µãƒ¢ãƒ¼ãƒ‰: {'æœ‰åŠ¹' if self.use_enhanced_mode else 'ç„¡åŠ¹'}", "info")
        return self.use_enhanced_mode

    def _sync_to_legacy_readonly(self):
        """AgentState â†’ Legacy CompanionCore ã¸ã®èª­ã¿å–ã‚Šå°‚ç”¨åŒæœŸ"""
        try:
            legacy_history = []
            user_msg = None
            for msg in self.state.conversation_history:
                if msg.role == "user":
                    user_msg = msg.content
                elif msg.role == "assistant" and user_msg is not None:
                    legacy_history.append({"user": user_msg, "assistant": msg.content, "timestamp": msg.timestamp})
                    user_msg = None
            
            if hasattr(self.legacy_companion, 'conversation_history'):
                self.legacy_companion.conversation_history = legacy_history
        except Exception as e:
            self.logger.warning(f"AgentState â†’ Legacy åŒæœŸã‚¨ãƒ©ãƒ¼: {e}")

    # ... (PlanTool and Code Execution methods remain the same) ...