#!/usr/bin/env python3
"""
Duckflowå¯¾è©±å“è³ªãƒ†ã‚¹ãƒˆ ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""
import sys
import json
import time
from datetime import datetime
from typing import List, Dict, Any
sys.path.append('.')

from codecrafter.main_v2 import DuckflowAgentV2
from codecrafter.base.config import config_manager
from codecrafter.state.agent_state import AgentState

class DialogueQualityTester:
    """å¯¾è©±å“è³ªãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        """ãƒ†ã‚¹ã‚¿ãƒ¼ã‚’åˆæœŸåŒ–"""
        self.config = config_manager.load_config()
        self.test_results = []
        self.start_time = datetime.now()
        
    def run_comprehensive_test(self) -> Dict[str, Any]:
        """åŒ…æ‹¬çš„ãªå¯¾è©±å“è³ªãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
        print("=== Duckflowå¯¾è©±å“è³ªãƒ†ã‚¹ãƒˆé–‹å§‹ ===")
        print(f"é–‹å§‹æ™‚åˆ»: {self.start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: {self.config.llm.provider}")
        print()
        
        # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹å®šç¾©
        test_cases = [
            {
                'id': 1,
                'category': 'åŸºæœ¬å¯¾è©±',
                'description': 'ã‚·ãƒ³ãƒ—ãƒ«ãªè³ªå•å¿œç­”ãƒ†ã‚¹ãƒˆ',
                'input': 'ã“ã‚“ã«ã¡ã¯ã€ã‚ãªãŸã¯ä½•ãŒã§ãã¾ã™ã‹ï¼Ÿ',
                'expected_features': ['greeting', 'capabilities_explanation']
            },
            {
                'id': 2, 
                'category': 'ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèªè¦æ±‚',
                'description': 'RoutingEngineæ±ºå®šè«–çš„ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãƒ†ã‚¹ãƒˆ',
                'input': 'CLAUDE.mdã®å†…å®¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„',
                'expected_features': ['file_read_request', 'routing_engine_trigger']
            },
            {
                'id': 3,
                'category': 'æ—¥æœ¬èªãƒ•ã‚¡ã‚¤ãƒ«å',
                'description': 'æ—¥æœ¬èªãƒ•ã‚¡ã‚¤ãƒ«åå‡¦ç†ãƒ†ã‚¹ãƒˆ',
                'input': 'ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒ»ãƒ¬ãƒãƒ¼ãƒˆ.mdã¨ã„ã†ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„',
                'expected_features': ['japanese_filename_support', 'file_existence_check']
            },
            {
                'id': 4,
                'category': 'ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆ†æ',
                'description': 'RAGçµ±åˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç†è§£ãƒ†ã‚¹ãƒˆ',
                'input': 'ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ä¸»è¦ãªæ©Ÿèƒ½ã¨ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’åˆ†æã—ã¦ãã ã•ã„',
                'expected_features': ['rag_integration', 'project_analysis', 'architecture_understanding']
            },
            {
                'id': 5,
                'category': 'è¤‡é›‘æŒ‡ç¤º',
                'description': 'LangGraphè¤‡æ•°ã‚¹ãƒ†ãƒƒãƒ—å‡¦ç†ãƒ†ã‚¹ãƒˆ', 
                'input': 'codecrafterãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æ§‹é€ ã‚’ç¢ºèªã—ã¦ã€é‡è¦ãªPythonãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç‰¹å®šã—ã€ãã‚Œã‚‰ã®å½¹å‰²ã‚’èª¬æ˜ã—ã¦ãã ã•ã„',
                'expected_features': ['multi_step_processing', 'directory_analysis', 'code_understanding']
            }
        ]
        
        # å„ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã‚’å®Ÿè¡Œ
        for i, test_case in enumerate(test_cases, 1):
            print(f"ğŸ§ª ãƒ†ã‚¹ãƒˆ {i}/{len(test_cases)}: {test_case['category']}")
            print(f"   {test_case['description']}")
            print(f"   å…¥åŠ›: {test_case['input']}")
            
            result = self.execute_single_test(test_case)
            self.test_results.append(result)
            
            print(f"   çµæœ: {'âœ… æˆåŠŸ' if result['success'] else 'âŒ å¤±æ•—'}")
            if not result['success']:
                print(f"   ã‚¨ãƒ©ãƒ¼: {result.get('error', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')}")
            print()
            
            # ãƒ†ã‚¹ãƒˆé–“ã®é–“éš”
            time.sleep(2)
        
        # çµæœé›†è¨ˆ
        summary = self.generate_summary()
        self.save_results(summary)
        
        return summary
    
    def execute_single_test(self, test_case: Dict[str, Any]) -> Dict[str, Any]:
        """å˜ä¸€ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã‚’å®Ÿè¡Œ"""
        test_result = {
            'test_id': test_case['id'],
            'category': test_case['category'],
            'input': test_case['input'],
            'start_time': datetime.now(),
            'success': False,
            'response': None,
            'error': None,
            'execution_time': 0,
            'routing_decision': None,
            'features_detected': []
        }
        
        try:
            # æ–°ã—ã„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‹å§‹
            agent = DuckflowAgentV2()
            
            # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
            start_time = time.time()
            
            # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡ï¼ˆLangGraphçµŒç”±ï¼‰
            agent._handle_orchestrated_conversation(test_case['input'])
            
            # æœ€æ–°ã®AIå¿œç­”ã‚’å–å¾—
            recent_messages = agent.state.get_recent_messages(1)
            if recent_messages and recent_messages[-1].role == 'assistant':
                response = recent_messages[-1].content
            else:
                response = "å¿œç­”ãªã—"
            
            end_time = time.time()
            test_result['execution_time'] = end_time - start_time
            test_result['response'] = response
            test_result['success'] = True
            
            # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆçŠ¶æ…‹ã‹ã‚‰è©³ç´°æƒ…å ±ã‚’å–å¾—
            if hasattr(agent, 'state'):
                # RoutingEngineã®æ±ºå®šã‚’ç¢ºèª
                if hasattr(agent.orchestrator, 'routing_engine'):
                    try:
                        routing_decision = agent.orchestrator.routing_engine.analyze_user_intent(
                            test_case['input'], []
                        )
                        test_result['routing_decision'] = {
                            'needs_file_read': routing_decision.needs_file_read,
                            'needs_file_list': routing_decision.needs_file_list,
                            'target_files': routing_decision.target_files,
                            'confidence': routing_decision.confidence,
                            'routing_reason': routing_decision.routing_reason
                        }
                    except Exception as e:
                        test_result['routing_decision'] = f"RoutingEngine error: {e}"
                
                # å®Ÿè¡Œã•ã‚ŒãŸãƒ„ãƒ¼ãƒ«å±¥æ­´
                if hasattr(agent.state, 'tool_executions'):
                    test_result['tools_executed'] = [
                        {
                            'tool_name': tool.tool_name,
                            'success': not bool(tool.error)
                        }
                        for tool in agent.state.tool_executions[-5:]  # æœ€æ–°5ä»¶
                    ]
            
            # æœŸå¾…ã•ã‚Œã‚‹æ©Ÿèƒ½ã®æ¤œå‡º
            test_result['features_detected'] = self.detect_features(
                test_case['input'], 
                response, 
                test_result.get('routing_decision'),
                test_case.get('expected_features', [])
            )
            
        except Exception as e:
            test_result['error'] = str(e)
            test_result['success'] = False
        
        test_result['end_time'] = datetime.now()
        return test_result
    
    def detect_features(self, input_text: str, response: str, routing_decision: Any, expected: List[str]) -> List[str]:
        """å¿œç­”ã‹ã‚‰æ©Ÿèƒ½ã®å‹•ä½œã‚’æ¤œå‡º"""
        detected = []
        
        # åŸºæœ¬çš„ãªå¿œç­”ãƒã‚§ãƒƒã‚¯
        if response and len(response.strip()) > 0:
            detected.append('response_generated')
        
        # ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œæ¤œå‡º
        if 'FILE_OPERATION:READ' in response:
            detected.append('file_read_operation')
        elif 'FILE_OPERATION:' in response:
            detected.append('file_operation')
        
        # RoutingEngineæ©Ÿèƒ½æ¤œå‡º
        if routing_decision and isinstance(routing_decision, dict):
            if routing_decision.get('needs_file_read'):
                detected.append('routing_engine_file_detection')
            if routing_decision.get('confidence', 0) > 0.8:
                detected.append('high_confidence_routing')
        
        # æ—¥æœ¬èªå‡¦ç†æ¤œå‡º
        if any(char in input_text for char in 'ã‚ã„ã†ãˆãŠã‹ããã‘ã“'):
            detected.append('japanese_processing')
        
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç†è§£æ¤œå‡º
        if any(keyword in response.lower() for keyword in ['architecture', 'structure', 'module', 'component']):
            detected.append('project_understanding')
        
        return detected
    
    def generate_summary(self) -> Dict[str, Any]:
        """ãƒ†ã‚¹ãƒˆçµæœã®è¦ç´„ã‚’ç”Ÿæˆ"""
        total_tests = len(self.test_results)
        successful_tests = sum(1 for result in self.test_results if result['success'])
        
        summary = {
            'test_session': {
                'start_time': self.start_time,
                'end_time': datetime.now(),
                'total_tests': total_tests,
                'successful_tests': successful_tests,
                'success_rate': successful_tests / total_tests if total_tests > 0 else 0,
                'llm_provider': self.config.llm.provider
            },
            'category_results': {},
            'feature_analysis': {},
            'performance_metrics': {
                'average_response_time': sum(r['execution_time'] for r in self.test_results) / total_tests,
                'fastest_response': min(r['execution_time'] for r in self.test_results),
                'slowest_response': max(r['execution_time'] for r in self.test_results)
            },
            'detailed_results': self.test_results
        }
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥çµæœ
        for result in self.test_results:
            category = result['category']
            if category not in summary['category_results']:
                summary['category_results'][category] = {'total': 0, 'successful': 0}
            
            summary['category_results'][category]['total'] += 1
            if result['success']:
                summary['category_results'][category]['successful'] += 1
        
        # æ©Ÿèƒ½æ¤œå‡ºåˆ†æ
        all_features = []
        for result in self.test_results:
            all_features.extend(result.get('features_detected', []))
        
        from collections import Counter
        feature_counts = Counter(all_features)
        summary['feature_analysis'] = dict(feature_counts)
        
        return summary
    
    def save_results(self, summary: Dict[str, Any]):
        """çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f'logs/dialogue_quality_test_{timestamp}.json'
        
        try:
            import os
            os.makedirs('logs', exist_ok=True)
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(summary, f, ensure_ascii=False, indent=2, default=str)
            
            print(f"ğŸ“Š ãƒ†ã‚¹ãƒˆçµæœã‚’ä¿å­˜: {filename}")
        except Exception as e:
            print(f"âš ï¸ çµæœä¿å­˜å¤±æ•—: {e}")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    tester = DialogueQualityTester()
    summary = tester.run_comprehensive_test()
    
    # çµæœè¡¨ç¤º
    print("=== ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼ ===")
    session = summary['test_session']
    print(f"å®Ÿè¡Œæ™‚é–“: {session['end_time'] - session['start_time']}")
    print(f"æˆåŠŸç‡: {session['successful_tests']}/{session['total_tests']} ({session['success_rate']:.1%})")
    print(f"å¹³å‡å¿œç­”æ™‚é–“: {summary['performance_metrics']['average_response_time']:.2f}ç§’")
    print()
    
    print("ã‚«ãƒ†ã‚´ãƒªåˆ¥çµæœ:")
    for category, results in summary['category_results'].items():
        success_rate = results['successful'] / results['total']
        print(f"  {category}: {results['successful']}/{results['total']} ({success_rate:.1%})")
    print()
    
    print("æ¤œå‡ºã•ã‚ŒãŸæ©Ÿèƒ½:")
    for feature, count in summary['feature_analysis'].items():
        print(f"  {feature}: {count}å›æ¤œå‡º")
    
    return summary

if __name__ == "__main__":
    main()