### **開発計画：高度な探索・分析エンジンの実装 (v1.0)**

**目標:** `Duckflow`が、広範囲にわたる抽象的なタスク（例：「PromptSmithのシナリオを教えて」）に対し、やみくもなファイルアクセスではなく、戦略的な調査と包括的な分析を行えるようにする。

**コア技術:**
1.  **知的ファイル探索 (Intelligent File Scouting):** LLMを使い、タスクに関連する可能性が高いファイルを優先順位付けする。
2.  **統合理解 (Integrated Comprehension):** 優先順位の高い複数ファイルを同時にコンテキストとし、全体像を分析・要約させる。

---

### **Phase 1: 知的ファイル探索機能の実装（最優先）**

**期間:** 1〜2週間
**目的:** エージェントの探索フェーズを、効率的で意図のあるものに変える。

#### **Step 1-1: `LLMService`の拡張**
*   **ファイル:** `duckflow/services/llm_services.py`
*   **タスク:** ファイル探索に特化した、新しいサブタスクLLMメソッドを追加する。
    ```python
    class LLMService:
        # ... (既存のメソッド) ...

        def prioritize_files_for_task(self, task_description: str, file_list: List[str]) -> List[str]:
            """
            タスク説明に基づき、調査すべきファイルの優先順位リストを生成する。
            高速モデル（Haikuなど）を使用する。
            """
            prompt = ChatPromptTemplate.from_template(
                """あなたはAI開発アシスタントです。
                ユーザーのタスク: "{task}"
                
                以下のファイルリストの中から、このタスクを解決するために最初に調査すべき、最も重要だと思われるファイルを5つまで選び、優先順位の高い順にリストアップしてください。
                
                考慮すべきヒント:
                - README, config, main, test, example といった名前のファイルを優先してください。
                - ディレクトリ構造も重要な手がかりです。
                
                ファイルリスト:
                {files}
                
                出力は、ファイルパスのリストのみを、一行に一つずつ記述してください。
                """
            )
            chain = prompt | self.fast_llm | StrOutputParser()
            
            # 出力された文字列を解析してリストに変換
            response_str = chain.invoke({"task": task_description, "files": "\n".join(file_list)})
            prioritized_list = [line.strip() for line in response_str.split('\n') if line.strip()]
            return prioritized_list
    ```

#### **Step 1-2: `1️⃣理解・計画ノード`のロジック変更**
*   **ファイル:** `duckflow/agent/orchestrator.py` 内の `_understanding_node`
*   **タスク:**
    1.  ユーザーの要求が「調査・分析」タイプであるかを判断する（簡単なキーワードマッチングや、専用の意図分類LLMサービスを利用）。
    2.  もし調査タイプなら、いきなり具体的な実行計画を立てるのではなく、**「調査計画」**を立てるように変更する。
    3.  **調査計画の実行:**
        *   `list_files(recursive=True)` を呼び出し、全ファイルリストを取得する。
        *   `LLMService.prioritize_files_for_task()` を呼び出し、優先順位リストを取得する。
        *   取得した優先順位リストを、`AgentState`の`task_plan`（または`investigation_plan`のような新しいフィールド）に保存する。
    *   **ノードの出力:** 次のステップが`2️⃣情報収集ノード`に進むように指示する。

**このフェーズの完了条件:**
*   ユーザーが「〇〇について調べて」と指示すると、`Duckflow`がコンソールに「以下のファイルを優先的に調査します: [file1.py, file2.py, ...]`」といったログを出力し、そのリストが`AgentState`に保存される。

---

### **Phase 2: 統合理解エンジンの実装**

**期間:** 1〜2週間
**目的:** 複数のファイルから得た断片的な情報を、一貫した「知識」に統合する。

#### **Step 2-1: `LLMService`のさらなる拡張**
*   **ファイル:** `duckflow/services/llm_services.py`
*   **タスク:** 複数ファイルの統合分析に特化した、新しいメソッドを追加する。
    ```python
    class LLMService:
        # ... (既存のメソッド) ...

        def synthesize_insights_from_files(self, task_description: str, files_with_content: Dict[str, str]) -> str:
            """
            複数のファイル内容を横断的に分析し、タスクに対する包括的な見解や要約を生成する。
            高性能モデル（Opus, Sonnetなど）を使用する。
            """
            # プロンプトのコンテキスト部分を作成
            context_str = ""
            for path, content in files_with_content.items():
                context_str += f"--- START OF FILE: {path} ---\n{content}\n--- END OF FILE: {path} ---\n\n"

            prompt = ChatPromptTemplate.from_template(
                """あなたはシニアソフトウェアアーキテクトです。
                ユーザーの最終的なタスク: "{task}"
                
                以下の複数のファイルの内容を横断的に分析し、上記タスクに対する包括的な回答や要約を生成してください。
                ファイル間の関係性や、全体的なアーキテクチャを考慮して、深い洞察を提供してください。
                
                【関連ファイルコンテキスト】
                {context}
                
                【あなたの分析結果】
                """
            )
            chain = prompt | self.creative_llm | StrOutputParser()
            return chain.invoke({"task": task_description, "context": context_str})
    ```

#### **Step 2-2: `2️⃣情報収集ノード`のロジック変更**
*   **ファイル:** `duckflow/agent/orchestrator.py` 内の `_gathering_node`
*   **タスク:**
    1.  `AgentState`から、Phase 1で作成された`investigation_plan`（調査すべきファイルリスト）を取得する。
    2.  リストにあるファイルを、ループまたは並列処理で`read_file`ツールを使って読み込む。
    3.  読み込んだファイルパスと内容を`Dict[str, str]`形式で収集する。
    4.  収集したデータを`LLMService.synthesize_insights_from_files()`に渡し、**プロジェクトの概要やタスクに対する分析結果**を取得する。
    5.  得られた分析結果を、`AgentState`の新しいフィールド（例: `project_summary: str`）に保存する。

#### **Step 2-3: `4️⃣評価・継続ノード`の役割変更**
*   **ファイル:** `duckflow/agent/orchestrator.py` 内の `_evaluation_node`
*   **タスク:**
    1.  `情報収集ノード`が完了した後、この評価ノードが呼び出される。
    2.  `AgentState`に`project_summary`が格納されていることを確認する。
    3.  この`project_summary`を、ユーザーへの**中間報告**としてUIに表示する。
    4.  次の行動として`REPLAN`（再計画）を決定し、`1️⃣理解・計画ノード`に処理を戻す。その際、`continuation_context`として「調査が完了し、プロジェクト概要の把握が完了しました。これを基に、具体的な実行計画を立ててください」という申し送りを渡す。

**このフェーズの完了条件:**
*   ユーザーが「PromptSmithのシナリオを教えて」と指示すると、`Duckflow`が関連ファイルをいくつか読み、その後「プロジェクトの分析結果：PromptSmithは、〇〇という目的で、ファイルAとファイルBを連携させる機能のようです...」といった、複数のファイル内容を統合した中間報告を提示できる。

---

### **Phase 3: テストと統合**

**期間:** 1週間
**目的:** 新しい探索・分析フローが、既存の実行フローとスムーズに連携し、全体として安定動作することを保証する。

*   **ユニットテスト:** `LLMService`に追加した2つの新しいメソッドに対するユニットテストを作成する。
*   **統合テスト:**
    *   **シナリオ1（調査タスク）:** 「〇〇について調べて」→ Phase 2で完了した中間報告が正しく表示されることを確認。
    *   **シナリオ2（調査→実行タスク）:** 「〇〇をリファクタリングして」→ 調査フェーズでプロジェクトを理解し、その理解に基づいた具体的な`write_file`計画を立て、実行できることを確認。
*   **プロンプト調整:** 実際の動作を見ながら、各サブタスクLLMに与えるプロンプトを微調整し、精度を向上させる。

この3フェーズの計画により、`Duckflow`は、現在の具体的なタスク実行能力に加えて、**人間のようにプロジェクトを調査・分析する**という、極めて高度で実用的な能力を獲得することができるでしょう。