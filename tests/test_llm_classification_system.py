"""
LLMãƒ™ãƒ¼ã‚¹TaskProfileåˆ†é¡ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹

å®Ÿè£…ã—ãŸæ©Ÿèƒ½ã®å‹•ä½œç¢ºèªã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
"""

import pytest
import json
from typing import Dict, Any
from pathlib import Path

# ãƒ†ã‚¹ãƒˆå¯¾è±¡ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from codecrafter.services.llm_service import llm_service
from codecrafter.services.task_profile_guardrail import task_profile_guardrail, confidence_adjuster
from codecrafter.services.hybrid_task_classifier import hybrid_task_classifier
from codecrafter.services.classification_manager import TaskProfileClassificationManager, ClassificationMode
from codecrafter.services.task_classifier import TaskProfileType


class TestLLMClassificationService:
    """LLMService.classify_task_profile()ã®ãƒ†ã‚¹ãƒˆ"""
    
    @pytest.fixture
    def sample_contexts(self):
        """ãƒ†ã‚¹ãƒˆç”¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿"""
        return {
            "basic": {},
            "with_files": {
                "detected_files": ["main.py", "config.py", "README.md"]
            },
            "with_history": {
                "recent_messages": [
                    {"role": "user", "content": "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®æ§‹é€ ã‚’æ•™ãˆã¦"},
                    {"role": "assistant", "content": "ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ..."}
                ]
            },
            "rich_context": {
                "detected_files": ["app.py", "tests.py"],
                "recent_messages": [
                    {"role": "user", "content": "ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’ç¢ºèªã—ãŸã„"}
                ],
                "workspace_manifest": {
                    "project_type": "Python Web Application"
                }
            }
        }
    
    def test_basic_classification_requests(self, sample_contexts):
        """åŸºæœ¬çš„ãªåˆ†é¡è¦æ±‚ã®ãƒ†ã‚¹ãƒˆ"""
        test_cases = [
            {
                "input": "README.mdã®å†…å®¹ã‚’æ•™ãˆã¦",
                "expected_profile": "INFORMATION_REQUEST",
                "min_confidence": 0.7
            },
            {
                "input": "README.mdã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦å“è³ªã‚’è©•ä¾¡ã—ã¦",
                "expected_profile": "ANALYSIS_REQUEST",
                "min_confidence": 0.7
            },
            {
                "input": "README.mdã‚’æ”¹å–„ã—ã¦èª­ã¿ã‚„ã™ãã—ã¦",
                "expected_profile": "MODIFICATION_REQUEST", 
                "min_confidence": 0.7
            },
            {
                "input": "Pythonã§ãƒ­ã‚°æ©Ÿèƒ½ã‚’å®Ÿè£…ã—ã¦",
                "expected_profile": "CREATION_REQUEST",
                "min_confidence": 0.8
            },
            {
                "input": "ãƒã‚°ã‚’æ¢ã—ã¦ä¿®æ­£ã—ã¦",
                "expected_profile": "MODIFICATION_REQUEST",
                "min_confidence": 0.6
            }
        ]
        
        for case in test_cases:
            try:
                result = llm_service.classify_task_profile(
                    case["input"], 
                    sample_contexts["basic"]
                )
                
                # åŸºæœ¬æ¤œè¨¼
                assert "profile_type" in result
                assert "confidence" in result
                assert "reasoning" in result
                
                # æœŸå¾…å€¤æ¤œè¨¼
                assert result["profile_type"] == case["expected_profile"], \
                    f"å…¥åŠ›: {case['input']}, æœŸå¾…: {case['expected_profile']}, å®Ÿéš›: {result['profile_type']}"
                
                assert result["confidence"] >= case["min_confidence"], \
                    f"ä¿¡é ¼åº¦ãŒä½ã™ãã¾ã™: {result['confidence']} < {case['min_confidence']}"
                
                print(f"âœ… {case['input']} â†’ {result['profile_type']} (ä¿¡é ¼åº¦: {result['confidence']:.2f})")
                
            except Exception as e:
                print(f"âŒ LLMåˆ†é¡ã‚¨ãƒ©ãƒ¼: {case['input']} - {e}")
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯åˆ†é¡ãŒå‹•ä½œã™ã‚‹ã“ã¨ã‚’ç¢ºèª
                fallback_result = llm_service._fallback_keyword_classification(case["input"])
                assert fallback_result["profile_type"] in [
                    "INFORMATION_REQUEST", "CREATION_REQUEST", "MODIFICATION_REQUEST"
                ]
                print(f"ğŸ”„ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‹•ä½œç¢ºèª: {fallback_result['profile_type']}")
    
    def test_contextual_classification(self, sample_contexts):
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä»˜ãåˆ†é¡ã®ãƒ†ã‚¹ãƒˆ"""
        test_request = "main.pyã¨config.pyã‚’æ¯”è¼ƒã—ã¦é•ã„ã‚’æ•™ãˆã¦"
        
        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãªã—ã®å ´åˆ
        result_basic = llm_service.classify_task_profile(test_request, sample_contexts["basic"])
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚ã‚Šã®å ´åˆ
        result_with_files = llm_service.classify_task_profile(test_request, sample_contexts["with_files"])
        
        # ä¸¡æ–¹ã¨ã‚‚ANALYSIS_REQUESTã«ãªã‚‹ã¯ãš
        assert result_basic["profile_type"] == "ANALYSIS_REQUEST"
        assert result_with_files["profile_type"] == "ANALYSIS_REQUEST"
        
        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚ã‚Šã®æ–¹ãŒä¿¡é ¼åº¦ãŒé«˜ã„ã¯ãš
        print(f"åŸºæœ¬: {result_basic['confidence']:.2f}, ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä»˜ã: {result_with_files['confidence']:.2f}")


class TestTaskProfileGuardrail:
    """ã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ"""
    
    def test_explicit_verb_override(self):
        """æ˜ç¢ºãªå‹•è©ã«ã‚ˆã‚‹ä¿®æ­£ãƒ†ã‚¹ãƒˆ"""
        test_cases = [
            {
                "request": "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¦æ–°ã—ã„æ©Ÿèƒ½ã‚’å®Ÿè£…ã—ã¦",
                "llm_result": {
                    "profile_type": "INFORMATION_REQUEST",  # èª¤åˆ†é¡
                    "confidence": 0.8,
                    "reasoning": "ãƒ†ã‚¹ãƒˆç”¨èª¤åˆ†é¡"
                },
                "expected_correction": "CREATION_REQUEST"
            },
            {
                "request": "ãƒã‚°ã‚’ä¿®æ­£ã—ã¦å‹•ä½œã‚’æ”¹å–„ã—ã¦",
                "llm_result": {
                    "profile_type": "INFORMATION_REQUEST",  # èª¤åˆ†é¡
                    "confidence": 0.7,
                    "reasoning": "ãƒ†ã‚¹ãƒˆç”¨èª¤åˆ†é¡"
                },
                "expected_correction": "MODIFICATION_REQUEST"
            }
        ]
        
        for case in test_cases:
            corrected = task_profile_guardrail.validate_and_correct(
                case["request"], case["llm_result"], {}
            )
            
            assert corrected["profile_type"] == case["expected_correction"], \
                f"ã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ«ä¿®æ­£å¤±æ•—: æœŸå¾… {case['expected_correction']}, å®Ÿéš› {corrected['profile_type']}"
            
            assert "guardrail_corrections" in corrected
            assert len(corrected["guardrail_corrections"]) > 0
            
            print(f"âœ… ã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ«ä¿®æ­£: {case['request'][:30]}... â†’ {corrected['profile_type']}")
    
    def test_file_scope_consistency(self):
        """ãƒ•ã‚¡ã‚¤ãƒ«ç¯„å›²æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ã®ãƒ†ã‚¹ãƒˆ"""
        request = "main.pyã¨config.pyã‚’æ¯”è¼ƒã—ã¦é•ã„ã‚’åˆ†æã—ã¦"
        llm_result = {
            "profile_type": "INFORMATION_REQUEST",  # èª¤åˆ†é¡
            "confidence": 0.6,
            "reasoning": "ãƒ†ã‚¹ãƒˆç”¨èª¤åˆ†é¡"
        }
        context = {
            "detected_files": ["main.py", "config.py"]
        }
        
        corrected = task_profile_guardrail.validate_and_correct(request, llm_result, context)
        
        assert corrected["profile_type"] == "ANALYSIS_REQUEST"
        assert "guardrail_corrections" in corrected
        print(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ«ç¯„å›²æ•´åˆæ€§ä¿®æ­£: INFORMATION_REQUEST â†’ ANALYSIS_REQUEST")
    
    def test_confidence_adjustment(self):
        """ä¿¡é ¼åº¦èª¿æ•´ã®ãƒ†ã‚¹ãƒˆ"""
        test_requests = [
            "README.mdã®å†…å®¹ã‚’æ•™ãˆã¦",  # æ˜ç¢ºãªè¦æ±‚
            "?",  # ä¸æ˜ç¢ºãªè¦æ±‚
            "main.pyã¨config.pyã‚’è©³ç´°ã«æ¯”è¼ƒåˆ†æã—ã¦ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®é•ã„ã¨æ”¹å–„ç‚¹ã‚’ç‰¹å®šã—ã¦ãã ã•ã„"  # è©³ç´°ãªè¦æ±‚
        ]
        
        for request in test_requests:
            adjusted_confidence = confidence_adjuster.adjust_confidence(0.8, request, {})
            
            assert 0.1 <= adjusted_confidence <= 1.0
            print(f"ä¿¡é ¼åº¦èª¿æ•´: '{request[:30]}...' â†’ {adjusted_confidence:.2f}")


class TestHybridTaskClassifier:
    """ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰åˆ†é¡ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ"""
    
    def test_hybrid_classification_success(self):
        """ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰åˆ†é¡ã®æˆåŠŸã‚±ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆ"""
        test_requests = [
            "README.mdã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦å“è³ªã‚’è©•ä¾¡ã—ã¦",
            "main.pyã¨config.pyã‚’æ¯”è¼ƒã—ã¦",
            "æ–°ã—ã„ãƒ­ã‚°æ©Ÿèƒ½ã‚’å®Ÿè£…ã—ã¦"
        ]
        
        for request in test_requests:
            result = hybrid_task_classifier.classify(request, {})
            
            # åŸºæœ¬ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ¤œè¨¼
            assert hasattr(result, 'profile_type')
            assert hasattr(result, 'confidence')
            assert hasattr(result, 'classification_method')
            
            # åˆ†é¡æ–¹æ³•ã®ç¢ºèª
            assert result.classification_method in [
                "llm", "rule", "hybrid_llm_primary", "hybrid_rule_primary", 
                "rule_fallback", "emergency_fallback"
            ]
            
            print(f"âœ… ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰åˆ†é¡: {request[:30]}... â†’ {result.profile_type.value} ({result.classification_method})")
    
    def test_fallback_mechanism(self):
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""
        # ç©ºã®è¦æ±‚ã§ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‹•ä½œã‚’ç¢ºèª
        result = hybrid_task_classifier.classify("", {})
        
        assert result.profile_type is not None
        assert result.confidence > 0
        assert "fallback" in result.classification_method.lower()
        
        print(f"âœ… ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‹•ä½œç¢ºèª: {result.classification_method}")
    
    def test_statistics_collection(self):
        """çµ±è¨ˆæƒ…å ±åé›†ã®ãƒ†ã‚¹ãƒˆ"""
        # è¤‡æ•°å›åˆ†é¡å®Ÿè¡Œ
        test_requests = [
            "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¦",
            "å†…å®¹ã‚’ç¢ºèªã—ã¦",
            "å•é¡Œã‚’åˆ†æã—ã¦"
        ]
        
        for request in test_requests:
            hybrid_task_classifier.classify(request, {})
        
        stats = hybrid_task_classifier.get_classification_statistics()
        
        assert "total_classifications" in stats
        assert stats["total_classifications"] >= len(test_requests)
        
        print(f"âœ… çµ±è¨ˆæƒ…å ±: {stats}")


class TestClassificationManager:
    """çµ±åˆåˆ†é¡ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®ãƒ†ã‚¹ãƒˆ"""
    
    def test_classification_modes(self):
        """å„åˆ†é¡ãƒ¢ãƒ¼ãƒ‰ã®ãƒ†ã‚¹ãƒˆ"""
        manager = TaskProfileClassificationManager()
        test_request = "README.mdã®å†…å®¹ã‚’æ•™ãˆã¦"
        
        modes_to_test = [
            ClassificationMode.RULE_ONLY,
            ClassificationMode.AUTO_SELECT
        ]
        
        for mode in modes_to_test:
            try:
                result = manager.classify(test_request, force_mode=mode)
                
                assert result.profile_type is not None
                assert result.confidence > 0
                
                print(f"âœ… {mode.value}ãƒ¢ãƒ¼ãƒ‰: {result.profile_type.value} (ä¿¡é ¼åº¦: {result.confidence:.2f})")
                
            except Exception as e:
                print(f"âŒ {mode.value}ãƒ¢ãƒ¼ãƒ‰ã§ã‚¨ãƒ©ãƒ¼: {e}")
                # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã‚‚ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‹•ä½œã‚’ç¢ºèª
                assert result is not None  # ä½•ã‚‰ã‹ã®çµæœãŒè¿”ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
    
    def test_auto_select_complexity_assessment(self):
        """è‡ªå‹•é¸æŠã®è¤‡é›‘åº¦è©•ä¾¡ãƒ†ã‚¹ãƒˆ"""
        manager = TaskProfileClassificationManager()
        
        test_cases = [
            {
                "request": "æ•™ãˆã¦",
                "expected_complexity": "low"
            },
            {
                "request": "main.pyã¨config.pyã‚’æ¯”è¼ƒåˆ†æã—ã¦å•é¡Œç‚¹ã‚’ç‰¹å®šã—ã€æ”¹å–„æ¡ˆã‚’ä½œæˆã—ã¦ãã ã•ã„",
                "context": {"detected_files": ["main.py", "config.py", "tests.py"]},
                "expected_complexity": "high"
            }
        ]
        
        for case in test_cases:
            context = case.get("context", {})
            complexity = manager._assess_request_complexity(case["request"], context)
            
            if case["expected_complexity"] == "low":
                assert complexity < 0.7
            else:
                assert complexity >= 0.7
            
            print(f"è¤‡é›‘åº¦è©•ä¾¡: '{case['request'][:30]}...' â†’ {complexity:.2f}")
    
    def test_health_check(self):
        """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""
        manager = TaskProfileClassificationManager()
        health = manager.health_check()
        
        assert "status" in health
        assert health["status"] in ["healthy", "degraded", "unhealthy"]
        assert "components" in health
        
        print(f"âœ… ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯: {health['status']}")
        for component, status in health["components"].items():
            print(f"  {component}: {'âœ…' if status.get('healthy') else 'âŒ'}")


class TestIntegrationScenarios:
    """çµ±åˆã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆ"""
    
    def test_real_world_scenarios(self):
        """å®Ÿéš›ã®ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆ"""
        manager = TaskProfileClassificationManager()
        
        scenarios = [
            {
                "name": "ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼è¦æ±‚",
                "request": "ã“ã®Pythonã‚³ãƒ¼ãƒ‰ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ã€å“è³ªã¨æ”¹å–„ç‚¹ã‚’æ•™ãˆã¦ãã ã•ã„",
                "context": {"detected_files": ["app.py"]},
                "expected_profile": TaskProfileType.ANALYSIS_REQUEST
            },
            {
                "name": "æ©Ÿèƒ½å®Ÿè£…è¦æ±‚", 
                "request": "ãƒ¦ãƒ¼ã‚¶ãƒ¼èªè¨¼ã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„",
                "context": {},
                "expected_profile": TaskProfileType.CREATION_REQUEST
            },
            {
                "name": "ãƒã‚°ä¿®æ­£è¦æ±‚",
                "request": "ãƒ­ã‚°ã‚¤ãƒ³æ™‚ã«ã‚¨ãƒ©ãƒ¼ãŒå‡ºã‚‹ã®ã§ä¿®æ­£ã—ã¦ãã ã•ã„",
                "context": {"detected_files": ["login.py", "auth.py"]},
                "expected_profile": TaskProfileType.MODIFICATION_REQUEST
            },
            {
                "name": "æƒ…å ±ç¢ºèªè¦æ±‚",
                "request": "è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’ç¢ºèªã—ãŸã„",
                "context": {"detected_files": ["config.yaml"]},
                "expected_profile": TaskProfileType.INFORMATION_REQUEST
            }
        ]
        
        for scenario in scenarios:
            try:
                result = manager.classify(scenario["request"], scenario["context"])
                
                # æœŸå¾…ã•ã‚Œã‚‹åˆ†é¡ã¨ã®ä¸€è‡´ã‚’ç¢ºèª
                is_correct = result.profile_type == scenario["expected_profile"]
                status = "âœ…" if is_correct else "âš ï¸"
                
                print(f"{status} {scenario['name']}: {result.profile_type.value} "
                      f"(æœŸå¾…: {scenario['expected_profile'].value}, ä¿¡é ¼åº¦: {result.confidence:.2f})")
                
                # ä¿¡é ¼åº¦ãŒè‘—ã—ãä½ã„å ´åˆã¯è­¦å‘Š
                if result.confidence < 0.5:
                    print(f"  âš ï¸ ä½ä¿¡é ¼åº¦: {result.confidence:.2f}")
                
            except Exception as e:
                print(f"âŒ {scenario['name']}ã§ã‚¨ãƒ©ãƒ¼: {e}")


def run_comprehensive_test():
    """åŒ…æ‹¬çš„ãªãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    print("ğŸ§ª LLMãƒ™ãƒ¼ã‚¹TaskProfileåˆ†é¡ã‚·ã‚¹ãƒ†ãƒ  åŒ…æ‹¬ãƒ†ã‚¹ãƒˆé–‹å§‹\n")
    
    # ãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–
    test_llm = TestLLMClassificationService()
    test_guardrail = TestTaskProfileGuardrail()
    test_hybrid = TestHybridTaskClassifier()
    test_manager = TestClassificationManager()
    test_integration = TestIntegrationScenarios()
    
    # ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæº–å‚™
    sample_contexts = test_llm.sample_contexts()
    
    try:
        print("=== 1. LLMåˆ†é¡ã‚µãƒ¼ãƒ“ã‚¹ãƒ†ã‚¹ãƒˆ ===")
        test_llm.test_basic_classification_requests(sample_contexts)
        print()
        
        print("=== 2. ã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ«ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ ===")
        test_guardrail.test_explicit_verb_override()
        test_guardrail.test_file_scope_consistency()
        print()
        
        print("=== 3. ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰åˆ†é¡ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ ===")
        test_hybrid.test_hybrid_classification_success()
        test_hybrid.test_fallback_mechanism()
        print()
        
        print("=== 4. çµ±åˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ãƒ†ã‚¹ãƒˆ ===")
        test_manager.test_classification_modes()
        test_manager.test_auto_select_complexity_assessment()
        print()
        
        print("=== 5. çµ±åˆã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆ ===")
        test_integration.test_real_world_scenarios()
        print()
        
        print("ğŸ‰ åŒ…æ‹¬ãƒ†ã‚¹ãƒˆå®Œäº†ï¼")
        
    except Exception as e:
        print(f"âŒ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    run_comprehensive_test()